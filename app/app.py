# app.py â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# GUI Streamlit â€“ PerÃº C-Inversiones  Â·  XGBoost (extensible)
# Cumple heurÃ­sticas bÃ¡sicas de Nielsen                                   Â»

import streamlit as st
import pandas as pd
import numpy as np
import xgboost as xgb
import json, pathlib, datetime as dt
from io import StringIO

# â”€â”€â”€ 0 Â· Config general â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(
    page_title="ğŸš€ Recomendador Cripto",
    page_icon="ğŸª™",
    layout="wide",
    initial_sidebar_state="expanded",
)
# â€¼ï¸ Para subir archivos >200 MB, arranca con:
#    streamlit run app.py --server.maxUploadSize=1024

# â”€â”€â”€ 1 Â· Rutas por defecto â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
BASE      = pathlib.Path(__file__).resolve().parent.parent
DATA_FP   = BASE / "data" / "crypto_ohlc_join_hourly_full.csv"
MODEL_DIR = BASE / "models"
XGB_PATH  = MODEL_DIR / "xgboost_optuna_optimized_20250710_022712.model"
XGB_CFG   = MODEL_DIR / "xgb_optuna_best_params_20250708_070015.json"

def dedup(seq):
    seen = set(); out = []
    for x in seq:
        if x not in seen:
            out.append(x); seen.add(x)
    return out

# â”€â”€â”€ 2 Â· Carga modelo XGBoost (cachÃ©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@st.cache_resource(show_spinner=True)
def load_xgboost():
    booster = xgb.Booster()
    booster.load_model(str(XGB_PATH))
    feats = None
    if XGB_CFG.exists():
        with open(XGB_CFG, encoding="utf-8") as f:
            cfg = json.load(f)
        for cand in [
            cfg.get("feature_names"),
            cfg.get("features"),
            cfg.get("learner", {}).get("feature_names"),
            cfg.get("learner", {})
               .get("gradient_booster", {})
               .get("model", {})
               .get("feature_names"),
        ]:
            if cand:
                feats = cand; break
    if not feats and getattr(booster, "feature_names", None):
        feats = booster.feature_names
    return booster, dedup(feats or [])

xgb_model, xgb_feats = load_xgboost()

# â”€â”€â”€ 3 Â· ConfiguraciÃ³n del modelo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODELS = {
    "XGBoost": {
        "model":      xgb_model,
        "features":   xgb_feats,
        "cat_feats":  ["narrative", "cluster_id"],
    },
}

# â”€â”€â”€ 4 Â· Lectura y preprocesado â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def read_default_df() -> pd.DataFrame:
    df = pd.read_csv(DATA_FP, low_memory=False)
    df["date"] = pd.to_datetime(df["timestamp"], unit="s", utc=True)
    # quedarnos solo con la fila mÃ¡s reciente por sÃ­mbolo
    return df.sort_values("date")\
             .groupby("symbol", as_index=False)\
             .tail(1)

def read_uploaded_df(uploaded: StringIO) -> pd.DataFrame:
    try:
        df = pd.read_csv(uploaded, low_memory=False)
    except Exception as e:
        raise ValueError(f"No se pudo leer el CSV: {e}")
    required = {"symbol","timestamp","narrative","market_cap","volume"}
    missing  = required - set(df.columns)
    if missing:
        raise ValueError(f"Faltan columnas obligatorias: {', '.join(missing)}")
    df["date"] = pd.to_datetime(df["timestamp"], unit="s", utc=True)
    return df.sort_values("date")\
             .groupby("symbol", as_index=False)\
             .tail(1)

def base_preprocess(df: pd.DataFrame) -> pd.DataFrame:
    X = df.copy()
    # narrativa
    X["narrative"] = X.get("narrative","unknown")\
                      .astype(str).fillna("unknown")
    # cluster_id como texto
    if "cluster_id" not in X.columns:
        X["cluster_id"] = "-1"
    X["cluster_id"] = pd.to_numeric(X["cluster_id"],
                                    errors="coerce")\
                       .fillna(-1).astype(int).astype(str)
    # numÃ©ricos crÃ­ticos
    for c in ("price","market_cap","volume"):
        if c in X.columns:
            X[c] = pd.to_numeric(X[c],
                                 errors="coerce")\
                     .fillna(0.0)
    return X

def encode_align(X: pd.DataFrame,
                 feat_list: list[str],
                 cat_cols: list[str]) -> pd.DataFrame:
    X2 = X.copy()
    # asegurar categorÃ­as mÃ­nimas
    for c in cat_cols:
        if c not in X2.columns:
            X2[c] = "unknown"
    # oneâ€hot
    X_enc = pd.get_dummies(X2,
                           columns=cat_cols,
                           dtype=float)
    # rellenar y reordenar
    for col in feat_list:
        if col not in X_enc.columns:
            X_enc[col] = 0.0
    return X_enc[feat_list]

# â”€â”€â”€ 5 Â· Sidebar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.header("ğŸ“‚ Dataset")
    up_file   = st.file_uploader("Subir CSV propio (opcional)", type="csv")
    top_k     = st.slider("Top N sugerencias", 5, 50, 20)
    narrative = st.selectbox("Narrativa",
                             ["Todas","ai","gaming","meme","rwa"])
    st.divider()
    if st.button("â“ Ayuda"):
        st.info(
            "1) (Opcional) sube tu CSV con OHLC+features.\n"
            "2) Elige narrativa.\n"
            "3) Explora ranking y mÃ©tricas; descarga.",
            icon="ğŸ’¡",
        )

# â”€â”€â”€ 6 Â· Leer dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    raw_df = read_uploaded_df(up_file) if up_file else read_default_df()
except ValueError as e:
    st.error(str(e), icon="âŒ")
    st.stop()

# â”€â”€â”€ 7 Â· Filtrar narrativa â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
df_f = raw_df if narrative=="Todas" else raw_df.query("narrative==@narrative")
if df_f.empty:
    st.warning("Sin datos para la narrativa elegida.", icon="âš ï¸")
    st.stop()

# â”€â”€â”€ 8 Â· Predecir â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
X_base = base_preprocess(df_f)
info   = MODELS["XGBoost"]
X_enc  = encode_align(X_base,
                      info["features"],
                      info["cat_feats"])
dmat   = xgb.DMatrix(X_enc.values,
                     feature_names=info["features"])
preds  = info["model"].predict(dmat)

df_f    = df_f.assign(exp_ret_30d=preds)\
               .sort_values("exp_ret_30d", ascending=False)
top_df  = df_f.head(top_k)

# â”€â”€â”€ 9 Â· MÃ©tricas rÃ¡pidas â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("### ğŸ“Š EstadÃ­sticas del subconjunto")
c1, c2, c3 = st.columns(3)
c1.metric("Activos analizados",         f"{len(df_f):,}")
c2.metric("Market Cap medio",           f"${df_f['market_cap'].mean():,.0f}")
c3.metric("Retorno esperado medio (30d)", f"{df_f['exp_ret_30d'].mean():+.2%}")

# â”€â”€â”€10 Â· Tabla principal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
basic = ["symbol","narrative","market_cap","exp_ret_30d"]
adv   = [c for c in df_f.columns if c not in basic+["date","timestamp"]]
showc = basic + adv

st.markdown(f"## ğŸ… Top {top_k} â€“ XGBoost")
st.caption(f"Actualizado: {dt.datetime.now(dt.timezone.utc):%Y-%m-%d %H:%M UTC}")
st.dataframe(
    top_df[showc]
         .style.format({"market_cap":"{:,.0f}",
                        "exp_ret_30d":"{:+.2%}"}),
    use_container_width=True, hide_index=True
)

# â”€â”€â”€11 Â· Descarga CSV â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.popover("â¬‡ï¸ Descargar"):
    if st.checkbox("Confirmo descarga"):
        st.download_button(
            "Descargar archivo",
            top_df.to_csv(index=False).encode(),
            f"recomendaciones_{dt.datetime.now(dt.timezone.utc):%Y%m%dT%H%M}.csv",
            mime="text/csv"
        )

# â”€â”€â”€12 Â· GrÃ¡ficas â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("### ğŸ“ˆ Retorno esperado vs CapitalizaciÃ³n de Mercado")
st.scatter_chart(
    top_df,
    x="market_cap",
    y="exp_ret_30d",
    size="volume",
    color="narrative",
    height=420,
)

# Nueva grÃ¡fica: Retorno promedio esperado por narrativa
st.markdown("### ğŸ“Š Retorno promedio esperado por narrativa")
narr_avg = df_f.groupby("narrative")["exp_ret_30d"]\
               .mean()\
               .sort_values(ascending=False) * 100
st.bar_chart(narr_avg, height=320)

st.caption("Â© 2025 PerÃº C-Inversiones Â· demo acadÃ©mica")
