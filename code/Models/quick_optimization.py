#!/usr/bin/env python3
"""
Script de configuraci√≥n r√°pida para optimizaci√≥n de hiperpar√°metros
Permite ejecutar optimizaciones espec√≠ficas y personalizadas
"""

import argparse
import sys
import os
from datetime import datetime

# Agregar paths necesarios
sys.path.append('/home/exodia/Documentos/MachineLearning_TF/code/EDA/utils')

def quick_xgboost_optimization(trials=30, timeout=600):
    """
    Optimizaci√≥n r√°pida solo para XGBoost
    """
    from crypto_hyperparameter_optimizer import CryptoHyperparameterOptimizer
    
    print("üî• OPTIMIZACI√ìN R√ÅPIDA - XGBOOST")
    print("=" * 50)
    
    optimizer = CryptoHyperparameterOptimizer()
    optimizer.load_and_prepare_data()
    
    study = optimizer.optimize_xgboost(n_trials=trials, timeout=timeout)
    optimizer.evaluate_best_models()
    optimizer.save_optimization_summary()
    
    print(f"\n‚úÖ XGBoost optimizado!")
    print(f"üèÜ Mejor AUC: {study.best_value:.4f}")
    print(f"üîß Mejores par√°metros: {study.best_params}")
    
    return study

def quick_lightgbm_optimization(trials=30, timeout=600):
    """
    Optimizaci√≥n r√°pida solo para LightGBM
    """
    from crypto_hyperparameter_optimizer import CryptoHyperparameterOptimizer
    
    print("üí° OPTIMIZACI√ìN R√ÅPIDA - LIGHTGBM")
    print("=" * 50)
    
    optimizer = CryptoHyperparameterOptimizer()
    optimizer.load_and_prepare_data()
    
    study = optimizer.optimize_lightgbm(n_trials=trials, timeout=timeout)
    optimizer.evaluate_best_models()
    optimizer.save_optimization_summary()
    
    print(f"\n‚úÖ LightGBM optimizado!")
    print(f"üèÜ Mejor AUC: {study.best_value:.4f}")
    print(f"üîß Mejores par√°metros: {study.best_params}")
    
    return study

def quick_catboost_optimization(trials=30, timeout=600):
    """
    Optimizaci√≥n r√°pida solo para CatBoost
    """
    from crypto_hyperparameter_optimizer import CryptoHyperparameterOptimizer
    
    print("üê± OPTIMIZACI√ìN R√ÅPIDA - CATBOOST")
    print("=" * 50)
    
    optimizer = CryptoHyperparameterOptimizer()
    optimizer.load_and_prepare_data()
    
    study = optimizer.optimize_catboost(n_trials=trials, timeout=timeout)
    optimizer.evaluate_best_models()
    optimizer.save_optimization_summary()
    
    print(f"\n‚úÖ CatBoost optimizado!")
    print(f"üèÜ Mejor AUC: {study.best_value:.4f}")
    print(f"üîß Mejores par√°metros: {study.best_params}")
    
    return study

def full_optimization(trials=50, timeout_per_model=1800):
    """
    Optimizaci√≥n completa de todos los modelos
    """
    from crypto_hyperparameter_optimizer import CryptoHyperparameterOptimizer
    
    print("üöÄ OPTIMIZACI√ìN COMPLETA - TODOS LOS MODELOS")
    print("=" * 60)
    
    optimizer = CryptoHyperparameterOptimizer()
    optimizer.load_and_prepare_data()
    
    optimizer.optimize_all_models(
        n_trials=trials,
        timeout_per_model=timeout_per_model
    )
    
    optimizer.evaluate_best_models()
    optimizer.generate_visualizations()
    optimizer.print_final_summary()
    
    return optimizer

def experimental_optimization(trials=100, timeout_per_model=3600):
    """
    Optimizaci√≥n experimental con m√°s trials y tiempo
    Para encontrar los mejores hiperpar√°metros posibles
    """
    from crypto_hyperparameter_optimizer import CryptoHyperparameterOptimizer
    
    print("üß™ OPTIMIZACI√ìN EXPERIMENTAL - B√öSQUEDA EXTENSIVA")
    print("=" * 70)
    print(f"‚ö†Ô∏è  Esta optimizaci√≥n puede tomar varias horas")
    print(f"üî¢ Trials por modelo: {trials}")
    print(f"‚è∞ Timeout por modelo: {timeout_per_model/60:.0f} minutos")
    
    optimizer = CryptoHyperparameterOptimizer()
    optimizer.load_and_prepare_data()
    
    optimizer.optimize_all_models(
        n_trials=trials,
        timeout_per_model=timeout_per_model
    )
    
    optimizer.evaluate_best_models()
    optimizer.generate_visualizations()
    optimizer.print_final_summary()
    
    return optimizer

def load_and_compare_studies():
    """
    Cargar estudios previos y compararlos
    """
    import pickle
    import json
    from pathlib import Path
    
    results_path = Path("../../optimization_results")
    
    print("üìä COMPARANDO ESTUDIOS PREVIOS")
    print("=" * 40)
    
    # Buscar archivos de resumen
    summary_files = list(results_path.glob("optimization_summary_*.json"))
    
    if not summary_files:
        print("‚ùå No se encontraron estudios previos")
        return
    
    print(f"üìÅ Encontrados {len(summary_files)} estudios:")
    
    all_results = []
    for summary_file in sorted(summary_files):
        with open(summary_file, 'r') as f:
            data = json.load(f)
            all_results.append(data)
        
        print(f"\nüìÖ {data['timestamp']}:")
        for model, score in data['best_scores'].items():
            print(f"   {model}: {score:.4f}")
    
    # Encontrar el mejor resultado general
    best_overall = None
    best_score = 0
    
    for result in all_results:
        for model, score in result['best_scores'].items():
            if score > best_score:
                best_score = score
                best_overall = (result['timestamp'], model, score, result['best_params'][model])
    
    if best_overall:
        timestamp, model, score, params = best_overall
        print(f"\nüèÜ MEJOR RESULTADO HIST√ìRICO:")
        print(f"   üìÖ Fecha: {timestamp}")
        print(f"   ü§ñ Modelo: {model}")
        print(f"   üìä AUC: {score:.4f}")
        print(f"   üîß Par√°metros: {params}")

def main():
    parser = argparse.ArgumentParser(description='Optimizaci√≥n de hiperpar√°metros para criptomonedas')
    parser.add_argument('--mode', choices=['quick-xgb', 'quick-lgb', 'quick-cat', 'full', 'experimental', 'compare'], 
                       default='full', help='Modo de optimizaci√≥n')
    parser.add_argument('--trials', type=int, default=50, help='N√∫mero de trials por modelo')
    parser.add_argument('--timeout', type=int, default=1800, help='Timeout en segundos por modelo')
    
    args = parser.parse_args()
    
    print(f"üöÄ Iniciando optimizaci√≥n en modo: {args.mode}")
    print(f"‚è∞ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    try:
        if args.mode == 'quick-xgb':
            quick_xgboost_optimization(args.trials, args.timeout)
        elif args.mode == 'quick-lgb':
            quick_lightgbm_optimization(args.trials, args.timeout)
        elif args.mode == 'quick-cat':
            quick_catboost_optimization(args.trials, args.timeout)
        elif args.mode == 'full':
            full_optimization(args.trials, args.timeout)
        elif args.mode == 'experimental':
            experimental_optimization(args.trials, args.timeout)
        elif args.mode == 'compare':
            load_and_compare_studies()
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è  Optimizaci√≥n interrumpida por el usuario")
    except Exception as e:
        print(f"\n‚ùå Error durante la optimizaci√≥n: {e}")
        raise

if __name__ == "__main__":
    main()
