#!/usr/bin/env python3
"""
üîß SISTEMA DE TESTING INTELIGENTE Y ADAPTATIVO
=================================================

Sistema que se adapta autom√°ticamente a las funciones disponibles
y genera tests robustos para el c√≥digo real existente.

‚úÖ Auto-detecci√≥n de funciones disponibles
‚úÖ Tests adaptativos basados en el c√≥digo real
‚úÖ Cobertura completa y robusta
‚úÖ Reporte profesional con m√©tricas avanzadas
"""

import sys
import os
import time
import importlib
import inspect
from pathlib import Path
from typing import Dict, List, Any
import warnings

# Configurar path
sys.path.append('.')

# Suprimir warnings para output m√°s limpio
warnings.filterwarnings('ignore')

class SmartTester:
    """Tester inteligente que se adapta al c√≥digo real"""
    
    def __init__(self):
        self.results = {}
        self.test_data = None
        self.available_functions = {}
        
    def create_smart_test_data(self):
        """Crear datos de prueba inteligentes"""
        import pandas as pd
        import numpy as np
        
        np.random.seed(42)
        
        # Datos realistas para criptomonedas
        n_obs = 200
        data = {
            'id': ['BTC', 'ETH', 'ADA', 'SOL', 'MATIC'] * (n_obs // 5),
            'symbol': [f'SYM{i%10}' for i in range(n_obs)],
            'name': [f'Token {i%20}' for i in range(n_obs)],
            'narrative': ['defi', 'gaming', 'ai', 'meme', 'rwa', 'infrastructure'] * (n_obs // 6 + 1),
            'close': np.random.lognormal(8, 1, n_obs),
            'market_cap': np.random.lognormal(25, 2, n_obs),
            'volume': np.random.lognormal(20, 1.5, n_obs),
            'date': pd.date_range('2023-01-01', periods=n_obs, freq='D')
        }
        
        # Ajustar longitudes para que coincidan
        for key in data:
            if len(data[key]) > n_obs:
                data[key] = data[key][:n_obs]
            elif len(data[key]) < n_obs:
                # Repetir hasta completar
                while len(data[key]) < n_obs:
                    data[key].extend(data[key][:min(len(data[key]), n_obs - len(data[key]))])
        
        df = pd.DataFrame(data)
        
        # Agregar algunos NaN para testing
        nan_indices = np.random.choice(df.index, 10, replace=False)
        df.loc[nan_indices[:5], 'market_cap'] = np.nan
        
        self.test_data = df
        print(f"üìä Datos de prueba creados: {len(df)} observaciones, {df['id'].nunique()} tokens √∫nicos")
        return df
    
    def discover_available_functions(self, module_name: str):
        """Descubrir funciones disponibles en un m√≥dulo"""
        try:
            module = importlib.import_module(f'utils.{module_name}')
            functions = {}
            
            for name, obj in inspect.getmembers(module):
                if inspect.isfunction(obj) and not name.startswith('_'):
                    sig = inspect.signature(obj)
                    functions[name] = {
                        'callable': obj,
                        'signature': sig,
                        'parameters': list(sig.parameters.keys()),
                        'docstring': obj.__doc__ or 'Sin documentaci√≥n'
                    }
            
            self.available_functions[module_name] = functions
            print(f"üîç M√≥dulo {module_name}: {len(functions)} funciones descubiertas")
            
            return functions
            
        except ImportError as e:
            print(f"‚ùå Error importando {module_name}: {e}")
            return {}
    
    def test_data_analysis_smart(self):
        """Tests inteligentes para data_analysis"""
        functions = self.discover_available_functions('data_analysis')
        
        tests_passed = 0
        total_tests = 0
        
        print("\nüî¨ === Testing data_analysis (Inteligente) ===")
        
        # Test de importaci√≥n
        total_tests += 1
        if functions:
            print("   ‚úÖ Test 1: M√≥dulo importado exitosamente")
            tests_passed += 1
        else:
            print("   ‚ùå Test 1: Error en importaci√≥n del m√≥dulo")
        
        # Test calculate_basic_metrics
        total_tests += 1
        if 'calculate_basic_metrics' in functions:
            try:
                metrics = functions['calculate_basic_metrics']['callable'](self.test_data)
                if isinstance(metrics, dict) and 'total_observations' in metrics:
                    print(f"   ‚úÖ Test 2: M√©tricas b√°sicas - {metrics['total_observations']} obs, {metrics.get('total_tokens', 'N/A')} tokens")
                    tests_passed += 1
                else:
                    print("   ‚ùå Test 2: Error en estructura de m√©tricas")
            except Exception as e:
                print(f"   ‚ùå Test 2: Error en m√©tricas b√°sicas - {e}")
        else:
            print("   ‚ö†Ô∏è  Test 2: Funci√≥n calculate_basic_metrics no disponible")
        
        # Test outliers (adaptativo)
        total_tests += 1
        outlier_functions = [name for name in functions.keys() if 'outlier' in name.lower()]
        if outlier_functions:
            try:
                func_name = outlier_functions[0]
                outliers = functions[func_name]['callable'](self.test_data, 'close')
                outlier_count = len(outliers) if hasattr(outliers, '__len__') else 0
                print(f"   ‚úÖ Test 3: Outliers detectados con {func_name} - {outlier_count} valores")
                tests_passed += 1
            except Exception as e:
                print(f"   ‚ùå Test 3: Error en detecci√≥n de outliers - {e}")
        else:
            print("   ‚ö†Ô∏è  Test 3: No hay funciones de detecci√≥n de outliers disponibles")
        
        # Test evaluaci√≥n de calidad
        total_tests += 1
        if 'evaluate_data_quality' in functions:
            try:
                from utils.config import QUALITY_THRESHOLDS
                metrics = functions['calculate_basic_metrics']['callable'](self.test_data)
                quality = functions['evaluate_data_quality']['callable'](metrics, QUALITY_THRESHOLDS)
                if isinstance(quality, dict) and 'overall_status' in quality:
                    print(f"   ‚úÖ Test 4: Calidad evaluada - {quality['overall_status']}")
                    tests_passed += 1
                else:
                    print("   ‚ùå Test 4: Error en estructura de calidad")
            except Exception as e:
                print(f"   ‚ùå Test 4: Error en evaluaci√≥n de calidad - {e}")
        else:
            print("   ‚ö†Ô∏è  Test 4: Funci√≥n evaluate_data_quality no disponible")
        
        # Test dominancia de mercado
        total_tests += 1
        if 'calculate_market_dominance' in functions:
            try:
                dominance = functions['calculate_market_dominance']['callable'](self.test_data)
                if hasattr(dominance, '__len__') and len(dominance) > 0:
                    print(f"   ‚úÖ Test 5: Dominancia calculada - {len(dominance)} grupos")
                    tests_passed += 1
                else:
                    print("   ‚ùå Test 5: Error en dominancia")
            except Exception as e:
                print(f"   ‚ùå Test 5: Error en dominancia - {e}")
        else:
            print("   ‚ö†Ô∏è  Test 5: Funci√≥n calculate_market_dominance no disponible")
        
        # Test reporte
        total_tests += 1
        if 'generate_summary_report' in functions:
            try:
                metrics = functions['calculate_basic_metrics']['callable'](self.test_data)
                from utils.config import QUALITY_THRESHOLDS
                quality = functions['evaluate_data_quality']['callable'](metrics, QUALITY_THRESHOLDS)
                report = functions['generate_summary_report']['callable'](metrics, quality)
                if isinstance(report, str) and len(report) > 50:
                    print(f"   ‚úÖ Test 6: Reporte generado - {len(report)} caracteres")
                    tests_passed += 1
                else:
                    print("   ‚ùå Test 6: Error en reporte")
            except Exception as e:
                print(f"   ‚ùå Test 6: Error en reporte - {e}")
        else:
            print("   ‚ö†Ô∏è  Test 6: Funci√≥n generate_summary_report no disponible")
        
        success_rate = (tests_passed / total_tests) * 100
        print(f"   üìä data_analysis: {tests_passed}/{total_tests} ({success_rate:.1f}%)")
        
        return tests_passed, total_tests
    
    def test_feature_engineering_smart(self):
        """Tests inteligentes para feature_engineering"""
        functions = self.discover_available_functions('feature_engineering')
        
        tests_passed = 0
        total_tests = 0
        
        print("\nüîß === Testing feature_engineering (Inteligente) ===")
        
        # Test de importaci√≥n
        total_tests += 1
        if functions:
            print("   ‚úÖ Test 1: M√≥dulo importado exitosamente")
            tests_passed += 1
        else:
            print("   ‚ùå Test 1: Error en importaci√≥n del m√≥dulo")
        
        # Test calculate_returns
        total_tests += 1
        if 'calculate_returns' in functions:
            try:
                df_returns = functions['calculate_returns']['callable'](self.test_data)
                return_cols = [col for col in df_returns.columns if 'ret_' in col]
                if len(return_cols) > 0:
                    print(f"   ‚úÖ Test 2: Retornos calculados - {return_cols}")
                    tests_passed += 1
                else:
                    print("   ‚ùå Test 2: No se generaron retornos")
            except Exception as e:
                print(f"   ‚ùå Test 2: Error en retornos - {e}")
        else:
            print("   ‚ö†Ô∏è  Test 2: Funci√≥n calculate_returns no disponible")
        
        # Test moving averages
        total_tests += 1
        ma_functions = [name for name in functions.keys() if 'moving' in name.lower() or 'ma' in name.lower()]
        if ma_functions:
            try:
                func_name = ma_functions[0]
                df_ma = functions[func_name]['callable'](self.test_data)
                ma_cols = [col for col in df_ma.columns if any(x in col for x in ['sma_', 'ma_', 'ema_'])]
                if len(ma_cols) > 0:
                    print(f"   ‚úÖ Test 3: Medias m√≥viles con {func_name} - {ma_cols}")
                    tests_passed += 1
                else:
                    print(f"   ‚ùå Test 3: No se generaron medias m√≥viles con {func_name}")
            except Exception as e:
                print(f"   ‚ùå Test 3: Error en medias m√≥viles - {e}")
        else:
            print("   ‚ö†Ô∏è  Test 3: No hay funciones de medias m√≥viles disponibles")
        
        # Test volatilidad
        total_tests += 1
        if 'calculate_volatility' in functions:
            try:
                # Primero calculamos retornos
                df_returns = functions['calculate_returns']['callable'](self.test_data)
                df_vol = functions['calculate_volatility']['callable'](df_returns)
                vol_cols = [col for col in df_vol.columns if 'vol_' in col]
                if len(vol_cols) > 0:
                    print(f"   ‚úÖ Test 4: Volatilidad calculada - {vol_cols}")
                    tests_passed += 1
                else:
                    print("   ‚ùå Test 4: No se calcul√≥ volatilidad")
            except Exception as e:
                print(f"   ‚ùå Test 4: Error en volatilidad - {e}")
        else:
            print("   ‚ö†Ô∏è  Test 4: Funci√≥n calculate_volatility no disponible")
        
        # Test technical features
        total_tests += 1
        tech_functions = [name for name in functions.keys() if 'technical' in name.lower() or 'feature' in name.lower()]
        if tech_functions:
            try:
                func_name = tech_functions[0]
                from utils.config import TECHNICAL_FEATURES
                df_tech = functions[func_name]['callable'](self.test_data, TECHNICAL_FEATURES)
                new_cols = len(df_tech.columns) - len(self.test_data.columns)
                if new_cols > 0:
                    print(f"   ‚úÖ Test 5: Features t√©cnicos con {func_name} - {new_cols} nuevas columnas")
                    tests_passed += 1
                else:
                    print(f"   ‚ùå Test 5: No se agregaron features con {func_name}")
            except Exception as e:
                print(f"   ‚ùå Test 5: Error en features t√©cnicos - {e}")
        else:
            print("   ‚ö†Ô∏è  Test 5: No hay funciones de features t√©cnicos disponibles")
        
        success_rate = (tests_passed / total_tests) * 100
        print(f"   üìä feature_engineering: {tests_passed}/{total_tests} ({success_rate:.1f}%)")
        
        return tests_passed, total_tests
    
    def test_visualizations_smart(self):
        """Tests inteligentes para visualizations"""
        functions = self.discover_available_functions('visualizations')
        
        tests_passed = 0
        total_tests = 0
        
        print("\nüìä === Testing visualizations (Inteligente) ===")
        
        # Test de importaci√≥n
        total_tests += 1
        if functions:
            print("   ‚úÖ Test 1: M√≥dulo importado exitosamente")
            tests_passed += 1
        else:
            print("   ‚ùå Test 1: Error en importaci√≥n del m√≥dulo")
        
        # Test para cada funci√≥n de visualizaci√≥n
        plot_functions = [name for name in functions.keys() if name.startswith('plot_')]
        
        for func_name in plot_functions:
            total_tests += 1
            try:
                from utils.config import NARRATIVE_COLORS
                
                # Intentar con diferentes combinaciones de par√°metros
                func_info = functions[func_name]
                params = func_info['parameters']
                
                if 'colors' in params:
                    fig = func_info['callable'](self.test_data, NARRATIVE_COLORS)
                else:
                    fig = func_info['callable'](self.test_data)
                
                if fig is not None:
                    print(f"   ‚úÖ Test {total_tests}: {func_name} generado exitosamente")
                    tests_passed += 1
                else:
                    print(f"   ‚ùå Test {total_tests}: {func_name} retorn√≥ None")
                    
            except Exception as e:
                print(f"   ‚ùå Test {total_tests}: Error en {func_name} - {str(e)[:50]}...")
        
        if not plot_functions:
            total_tests += 1
            print("   ‚ö†Ô∏è  Test 2: No se encontraron funciones de visualizaci√≥n")
        
        success_rate = (tests_passed / total_tests) * 100
        print(f"   üìä visualizations: {tests_passed}/{total_tests} ({success_rate:.1f}%)")
        
        return tests_passed, total_tests
    
    def test_config_smart(self):
        """Tests inteligentes para config"""
        print("\n‚öôÔ∏è === Testing config (Inteligente) ===")
        
        tests_passed = 0
        total_tests = 0
        
        # Test de importaci√≥n b√°sica
        total_tests += 1
        try:
            import utils.config
            print("   ‚úÖ Test 1: M√≥dulo config importado exitosamente")
            tests_passed += 1
        except ImportError as e:
            print(f"   ‚ùå Test 1: Error importando config - {e}")
        
        # Descubrir qu√© variables est√°n disponibles
        config_vars = {}
        try:
            import utils.config as config
            config_vars = {name: getattr(config, name) for name in dir(config) if not name.startswith('_')}
        except:
            pass
        
        # Test variables importantes
        important_vars = ['NARRATIVE_COLORS', 'QUALITY_THRESHOLDS', 'ANALYSIS_CONFIG', 'TECHNICAL_FEATURES']
        
        for var_name in important_vars:
            total_tests += 1
            if var_name in config_vars:
                var_value = config_vars[var_name]
                if isinstance(var_value, dict) and len(var_value) > 0:
                    print(f"   ‚úÖ Test {total_tests}: {var_name} configurado - {len(var_value)} elementos")
                    tests_passed += 1
                elif isinstance(var_value, (list, tuple)) and len(var_value) > 0:
                    print(f"   ‚úÖ Test {total_tests}: {var_name} configurado - {len(var_value)} elementos")
                    tests_passed += 1
                else:
                    print(f"   ‚ö†Ô∏è  Test {total_tests}: {var_name} existe pero est√° vac√≠o")
            else:
                print(f"   ‚ö†Ô∏è  Test {total_tests}: {var_name} no encontrado")
        
        success_rate = (tests_passed / total_tests) * 100
        print(f"   üìä config: {tests_passed}/{total_tests} ({success_rate:.1f}%)")
        
        return tests_passed, total_tests
    
    def run_comprehensive_tests(self):
        """Ejecutar todos los tests inteligentes"""
        start_time = time.time()
        
        print("üß†" + "="*60)
        print("üöÄ SISTEMA DE TESTING INTELIGENTE Y ADAPTATIVO")
        print("üß†" + "="*60)
        
        # Crear datos de prueba
        self.create_smart_test_data()
        
        # Ejecutar tests inteligentes
        all_results = []
        
        all_results.append(self.test_data_analysis_smart())
        all_results.append(self.test_feature_engineering_smart())
        all_results.append(self.test_visualizations_smart())
        all_results.append(self.test_config_smart())
        
        # Calcular estad√≠sticas finales
        total_passed = sum(result[0] for result in all_results)
        total_tests = sum(result[1] for result in all_results)
        overall_success = (total_passed / total_tests * 100) if total_tests > 0 else 0
        
        execution_time = time.time() - start_time
        
        # Reporte final
        print("\nüèÅ" + "="*60)
        print("üìä REPORTE FINAL INTELIGENTE")
        print("üèÅ" + "="*60)
        print(f"‚è±Ô∏è  Tiempo de ejecuci√≥n: {execution_time:.2f}s")
        print(f"üìà Tasa de √©xito adaptativa: {overall_success:.1f}%")
        print(f"‚úÖ Tests pasados: {total_passed}")
        print(f"‚ùå Tests fallidos: {total_tests - total_passed}")
        print(f"üß™ Total tests ejecutados: {total_tests}")
        
        print(f"\nüîç Funciones descubiertas por m√≥dulo:")
        for module_name, functions in self.available_functions.items():
            print(f"   üì¶ {module_name}: {len(functions)} funciones")
            for func_name in list(functions.keys())[:3]:  # Mostrar las primeras 3
                print(f"      ‚Ä¢ {func_name}")
            if len(functions) > 3:
                print(f"      ‚Ä¢ ... y {len(functions) - 3} m√°s")
        
        print("\nüéØ" + "="*60)
        if overall_success >= 90:
            print("üéâ ¬°EXCELENTE! Sistema completamente funcional y bien estructurado")
        elif overall_success >= 75:
            print("üëç ¬°BUENO! Sistema funcional con estructura s√≥lida")
        elif overall_success >= 60:
            print("‚úÖ FUNCIONAL. Sistema operativo con algunas limitaciones")
        else:
            print("‚ö†Ô∏è  B√ÅSICO. Sistema funciona pero necesita expansi√≥n")
        print("üéØ" + "="*60)
        
        return overall_success, total_passed, total_tests

def main():
    """Funci√≥n principal"""
    tester = SmartTester()
    tester.run_comprehensive_tests()

if __name__ == "__main__":
    main()
