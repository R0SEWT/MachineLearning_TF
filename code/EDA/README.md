# EDA Crypto - An√°lisis Modularizado

Este directorio contiene el an√°lisis exploratorio de datos (EDA) para criptomonedas en versi√≥n modularizada, lo que permite mayor reutilizaci√≥n, mantenimiento y escalabilidad del c√≥digo.

## üìÅ Estructura de Archivos

```
EDA/
‚îú‚îÄ‚îÄ EDA_crypto.ipynb           # Notebook original mejorado
‚îú‚îÄ‚îÄ EDA_crypto_modular.ipynb   # Notebook completamente modularizado
‚îú‚îÄ‚îÄ README.md                  # Este archivo
‚îî‚îÄ‚îÄ utils/                     # M√≥dulos de utilidades
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ config.py              # Configuraciones y constantes
    ‚îú‚îÄ‚îÄ data_analysis.py       # Funciones de an√°lisis estad√≠stico
    ‚îú‚îÄ‚îÄ visualizations.py      # Funciones de visualizaci√≥n
    ‚îî‚îÄ‚îÄ feature_engineering.py # Funciones de ingenier√≠a de caracter√≠sticas
```

## üîß M√≥dulos Creados

### 1. `config.py`
Contiene todas las configuraciones centralizadas:
- **Colores de narrativas**: Paleta consistente para visualizaciones
- **Rutas del proyecto**: Gesti√≥n autom√°tica de paths
- **Configuraciones de an√°lisis**: Par√°metros para algoritmos
- **Umbrales de calidad**: Criterios de evaluaci√≥n del dataset
- **Columnas esperadas**: Definici√≥n de estructura de datos

### 2. `data_analysis.py`
Funciones especializadas para an√°lisis estad√≠stico:
- `calculate_basic_metrics()`: M√©tricas b√°sicas del dataset
- `evaluate_data_quality()`: Evaluaci√≥n autom√°tica de calidad
- `detect_outliers_iqr()`: Detecci√≥n de outliers por IQR
- `calculate_distribution_stats()`: Estad√≠sticas de distribuci√≥n
- `calculate_market_dominance()`: An√°lisis de dominancia de mercado
- `generate_summary_report()`: Generaci√≥n de reportes autom√°ticos

### 3. `visualizations.py`
Funciones especializadas para visualizaci√≥n:
- `plot_narrative_distribution()`: Distribuci√≥n por narrativas
- `plot_market_cap_analysis()`: An√°lisis visual de market cap
- `plot_temporal_analysis()`: Patrones temporales avanzados
- `plot_returns_analysis()`: An√°lisis de distribuciones de retornos
- `plot_quality_dashboard()`: Dashboard ejecutivo de calidad

### 4. `feature_engineering.py`
Funciones para creaci√≥n de caracter√≠sticas:
- `calculate_returns()`: Retornos para m√∫ltiples per√≠odos
- `calculate_moving_averages()`: Promedios m√≥viles
- `calculate_volatility()`: Volatilidad m√≥vil
- `calculate_bollinger_bands()`: Bandas de Bollinger
- `create_technical_features()`: Pipeline completo de features
- `filter_tokens_by_history()`: Filtrado por hist√≥rico m√≠nimo
- `prepare_ml_dataset()`: Preparaci√≥n final para ML
- `add_clustering_features()`: Segmentaci√≥n autom√°tica

## üöÄ Uso R√°pido

### Importar M√≥dulos
```python
import sys
sys.path.append('./utils')

from config import NARRATIVE_COLORS, get_project_paths, ANALYSIS_CONFIG
from data_analysis import calculate_basic_metrics, evaluate_data_quality
from visualizations import plot_quality_dashboard
from feature_engineering import create_technical_features
```

### An√°lisis B√°sico
```python
# Cargar configuraci√≥n
paths = get_project_paths()
df = pd.read_csv(paths['data'])

# Calcular m√©tricas
metrics = calculate_basic_metrics(df)
quality = evaluate_data_quality(metrics, QUALITY_THRESHOLDS)

# Visualizar calidad
fig = plot_quality_dashboard(metrics, quality, df, NARRATIVE_COLORS)
```

### Feature Engineering
```python
# Crear caracter√≠sticas t√©cnicas
df_features = create_technical_features(df, TECHNICAL_FEATURES)

# Preparar para ML
X, y = prepare_ml_dataset(df_features)
```

## ‚úÖ Beneficios de la Modularizaci√≥n

### üîÑ Reutilizaci√≥n
- Las funciones pueden usarse en otros proyectos de crypto
- C√≥digo base para an√°lisis similares
- Bibliotecas internas reutilizables

### üõ† Mantenimiento
- Cada funci√≥n tiene responsabilidad √∫nica
- F√°cil localizar y corregir bugs
- Actualizaciones modulares sin afectar todo el c√≥digo

### üìñ Legibilidad
- Notebooks m√°s claros y enfocados en el flujo
- Separaci√≥n entre l√≥gica y presentaci√≥n
- Documentaci√≥n centralizada

### üß™ Testeo
- Cada funci√≥n puede probarse independientemente
- Tests unitarios m√°s f√°ciles de implementar
- Validaci√≥n modular de funcionalidad

### ‚öôÔ∏è Configuraci√≥n
- Par√°metros centralizados y f√°ciles de modificar
- Configuraciones por ambiente (dev, prod)
- Gesti√≥n consistente de constantes

### üìà Escalabilidad
- F√°cil a√±adir nuevas funcionalidades
- Arquitectura extensible
- Soporte para m√∫ltiples datasets

## üéØ Casos de Uso

### 1. An√°lisis R√°pido de Nuevo Dataset
```python
# Solo cambiar la ruta del archivo
paths['data'] = 'nuevo_dataset.csv'
df = pd.read_csv(paths['data'])

# El resto del an√°lisis es autom√°tico
metrics = calculate_basic_metrics(df)
quality = evaluate_data_quality(metrics, QUALITY_THRESHOLDS)
```

### 2. Personalizaci√≥n de Visualizaciones
```python
# Modificar colores para nuevas narrativas
NARRATIVE_COLORS['defi'] = '#ffa726'
NARRATIVE_COLORS['nft'] = '#ab47bc'

# Las visualizaciones se adaptan autom√°ticamente
fig = plot_narrative_distribution(df, NARRATIVE_COLORS)
```

### 3. Pipeline de Feature Engineering
```python
# Configurar features personalizadas
custom_config = {
    'returns': [1, 3, 7, 14, 30],
    'moving_averages': [5, 10, 20, 50],
    'volatility_window': 14
}

# Aplicar pipeline
df_features = create_technical_features(df, custom_config)
```

## üî¨ Testing y Validaci√≥n

### Tests Recomendados
```python
# Test de funciones b√°sicas
def test_calculate_basic_metrics():
    sample_df = create_sample_dataframe()
    metrics = calculate_basic_metrics(sample_df)
    assert 'total_observations' in metrics
    assert metrics['total_observations'] > 0

# Test de visualizaciones
def test_plot_quality_dashboard():
    fig = plot_quality_dashboard(metrics, quality, df, NARRATIVE_COLORS)
    assert fig is not None
    assert len(fig.axes) == 6
```

## üìä Configuraciones Disponibles

### Narrativas Soportadas
- `meme`: Meme coins
- `rwa`: Real World Assets
- `gaming`: Gaming tokens
- `ai`: Artificial Intelligence
- `defi`: Decentralized Finance
- `infrastructure`: Infrastructure tokens

### Par√°metros Configurables
- **Outlier contamination**: 5% por defecto
- **Hist√≥rico m√≠nimo**: 60 d√≠as
- **Ventana de volatilidad**: 30 d√≠as
- **Ventana de correlaci√≥n**: 90 d√≠as
- **N√∫mero de clusters**: 4 por defecto

## üöÄ Pr√≥ximos Pasos

### Mejoras Planificadas
1. **Testing**: Implementar suite completa de tests
2. **Logging**: Sistema de logs para debugging
3. **Performance**: Optimizaci√≥n de funciones cr√≠ticas
4. **Validaci√≥n**: Validaci√≥n robusta de inputs
5. **Documentation**: Documentaci√≥n API detallada
6. **CI/CD**: Integraci√≥n continua

### Extensiones Posibles
1. **An√°lisis de sentimiento**: M√≥dulo para datos de redes sociales
2. **An√°lisis t√©cnico avanzado**: M√°s indicadores t√©cnicos
3. **Risk metrics**: M√©tricas de riesgo especializadas
4. **Portfolio analysis**: An√°lisis de portafolios
5. **Real-time**: Soporte para datos en tiempo real

## üìû Soporte

Para preguntas sobre el uso de estos m√≥dulos:
1. Revisar la documentaci√≥n en cada archivo
2. Consultar los ejemplos en los notebooks
3. Verificar los tests unitarios
4. Contactar al equipo de desarrollo

---

**Versi√≥n**: 1.0  
**√öltima actualizaci√≥n**: 8 de julio de 2025  
**Autor**: Equipo ML-TF-G  
**Estado**: Producci√≥n
