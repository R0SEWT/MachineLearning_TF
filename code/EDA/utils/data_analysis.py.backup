"""
Módulo de utilidades para análisis estadístico y de calidad de datos
"""

# Imports estándar
from typing import Dict, List, Tuple, Optional, Any

# Imports de terceros
import pandas as pd
import numpy as np

def calculate_basic_metrics(df: pd.DataFrame) -> Dict[str, Any]:
    """
    Calcula métricas básicas del dataset
    
    Args:
        df: DataFrame con los datos
        
    Returns:
        Dict con métricas básicas
    """
    metrics = {
        'total_observations': len(df),
        'total_tokens': df['id'].nunique() if 'id' in df.columns else 0,
        'total_narratives': df['narrative'].nunique() if 'narrative' in df.columns else 0,
        'completeness': (1 - df.isnull().sum().sum() / (len(df) * len(df.columns))) * 100,
        'duplicates_pct': (df.duplicated().sum() / len(df)) * 100 if len(df) > 0 else 0
    }
    
    if 'date' in df.columns:
        try:
            df_temp = df.copy()
            df_temp['date'] = pd.to_datetime(df_temp['date'])
            metrics['date_range'] = (df_temp['date'].max() - df_temp['date'].min()).days
            metrics['date_min'] = df_temp['date'].min()
            metrics['date_max'] = df_temp['date'].max()
        except:
            metrics['date_range'] = 0
    else:
        metrics['date_range'] = 0
    
    return metrics

# Alias para backward compatibility y consistencia
def get_basic_metrics(df: pd.DataFrame) -> Dict[str, Any]:
    """
    Alias para calculate_basic_metrics - Calcula métricas básicas del dataset
    
    Args:
        df: DataFrame con los datos
        
    Returns:
        Dict con métricas básicas
    """
    return calculate_basic_metrics(df)

def evaluate_data_quality(metrics: Dict[str, Any], thresholds: Dict) -> Dict[str, Any]:
    """
    Evalúa la calidad del dataset basándose en métricas y umbrales
    
    Args:
        metrics: Diccionario con métricas del dataset
        thresholds: Diccionario con umbrales de calidad
        
    Returns:
        Dict con evaluación de calidad
    """
    criteria_scores = []
    
    # Volumen de datos
    if metrics['total_observations'] > thresholds['excellent']['observations']:
        vol_score = ('🟢', 'verde')
    elif metrics['total_observations'] > thresholds['good']['observations']:
        vol_score = ('🟡', 'amarillo')
    else:
        vol_score = ('🔴', 'rojo')
    criteria_scores.append(vol_score[1])
    
    # Completitud
    if metrics['completeness'] > thresholds['excellent']['completeness']:
        comp_score = ('🟢', 'verde')
    elif metrics['completeness'] > thresholds['good']['completeness']:
        comp_score = ('🟡', 'amarillo')
    else:
        comp_score = ('🔴', 'rojo')
    criteria_scores.append(comp_score[1])
    
    # Diversidad narrativas
    if metrics['total_narratives'] >= thresholds['excellent']['narratives']:
        div_score = ('🟢', 'verde')
    elif metrics['total_narratives'] >= thresholds['good']['narratives']:
        div_score = ('🟡', 'amarillo')
    else:
        div_score = ('🔴', 'rojo')
    criteria_scores.append(div_score[1])
    
    # Rango temporal
    if metrics['date_range'] > thresholds['excellent']['temporal_days']:
        temp_score = ('🟢', 'verde')
    elif metrics['date_range'] > thresholds['good']['temporal_days']:
        temp_score = ('🟡', 'amarillo')
    else:
        temp_score = ('🔴', 'rojo')
    criteria_scores.append(temp_score[1])
    
    # Calcular score general
    score_values = {'verde': 2, 'amarillo': 1, 'rojo': 0}
    total_score = sum([score_values[color] for color in criteria_scores])
    max_score = len(criteria_scores) * 2
    readiness_percentage = (total_score / max_score) * 100
    
    if readiness_percentage >= 75:
        overall_status = "🟢 EXCELENTE"
    elif readiness_percentage >= 50:
        overall_status = "🟡 BUENO"
    else:
        overall_status = "🔴 REQUIERE MEJORAS"
    
    return {
        'vol_score': vol_score,
        'comp_score': comp_score,
        'div_score': div_score,
        'temp_score': temp_score,
        'criteria_scores': criteria_scores,
        'readiness_percentage': readiness_percentage,
        'overall_status': overall_status
    }

def detect_outliers_iqr(series: pd.Series) -> Tuple[int, float]:
    """
    Detecta outliers usando el método IQR
    
    Args:
        series: Serie de datos para analizar
        
    Returns:
        Tuple con (número de outliers, porcentaje)
    """
    if len(series) == 0:
        return 0, 0.0
        
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    outliers = series[(series < lower_bound) | (series > upper_bound)]
    return len(outliers), (len(outliers) / len(series) * 100)

def calculate_distribution_stats(series: pd.Series) -> Dict[str, float]:
    """
    Calcula estadísticas de distribución para una serie
    
    Args:
        series: Serie de datos
        
    Returns:
        Dict con estadísticas de distribución
    """
    if len(series) == 0:
        return {
            'skewness': np.nan,
            'kurtosis': np.nan,
            'is_normal': False
        }
    
    skewness = series.skew()
    kurtosis_val = series.kurtosis()
    is_normal = abs(skewness) < 0.5 and abs(kurtosis_val) < 3
    
    return {
        'skewness': skewness,
        'kurtosis': kurtosis_val,
        'is_normal': is_normal,
        'mean': series.mean(),
        'std': series.std(),
        'min': series.min(),
        'max': series.max()
    }

def calculate_market_dominance(df: pd.DataFrame, group_col: str = 'narrative', 
                             value_col: str = 'market_cap') -> pd.Series:
    """
    Calcula la dominancia de mercado por grupo
    
    Args:
        df: DataFrame con los datos
        group_col: Columna para agrupar
        value_col: Columna con valores para sumar
        
    Returns:
        Serie con dominancia por grupo
    """
    if group_col not in df.columns or value_col not in df.columns:
        return pd.Series(dtype=float)
    
    return df.groupby(group_col)[value_col].sum().sort_values(ascending=False)

def filter_extreme_values(series: pd.Series, quantiles: Tuple[float, float] = (0.01, 0.99)) -> pd.Series:
    """
    Filtra valores extremos basándose en cuantiles
    
    Args:
        series: Serie de datos
        quantiles: Tuple con cuantiles inferior y superior
        
    Returns:
        Serie filtrada
    """
    if len(series) == 0:
        return series
    
    lower_q, upper_q = quantiles
    lower_bound = series.quantile(lower_q)
    upper_bound = series.quantile(upper_q)
    
    return series[(series >= lower_bound) & (series <= upper_bound)]

def calculate_correlation_matrix(df: pd.DataFrame, tokens: List[str], 
                               date_col: str = 'date', value_col: str = 'close') -> pd.DataFrame:
    """
    Calcula matriz de correlación para tokens seleccionados
    
    Args:
        df: DataFrame con los datos
        tokens: Lista de tokens para incluir
        date_col: Columna de fecha
        value_col: Columna de valores
        
    Returns:
        DataFrame con matriz de correlación
    """
    if date_col not in df.columns or value_col not in df.columns:
        return pd.DataFrame()
    
    # Crear matriz de retornos
    returns_matrix = pd.DataFrame()
    
    for token in tokens:
        token_data = df[df['id'] == token].sort_values(date_col)
        if len(token_data) > 30:  # Suficientes observaciones
            token_returns = token_data.set_index(date_col)[value_col].pct_change().dropna()
            returns_matrix[token] = token_returns
    
    if returns_matrix.empty:
        return pd.DataFrame()
        
    return returns_matrix.corr()

def generate_summary_report(metrics: Dict[str, Any], quality_eval: Dict[str, Any]) -> str:
    """
    Genera un resumen textual del análisis
    
    Args:
        metrics: Métricas del dataset
        quality_eval: Evaluación de calidad
        
    Returns:
        String con el resumen
    """
    report = f"""
📊 RESUMEN EJECUTIVO DEL DATASET

📈 MÉTRICAS PRINCIPALES:
  • Observaciones totales: {metrics['total_observations']:,}
  • Tokens únicos: {metrics['total_tokens']:,}
  • Narrativas: {metrics['total_narratives']}
  • Completitud general: {metrics['completeness']:.1f}%
  • Rango temporal: {metrics['date_range']} días

✅ CALIDAD DEL DATASET:
  • Score de preparación: {quality_eval['readiness_percentage']:.0f}%
  • Estado general: {quality_eval['overall_status']}

🎯 RECOMENDACIONES:
"""
    
    if quality_eval['readiness_percentage'] >= 75:
        report += """  ✅ Dataset LISTO para modelado avanzado
  🚀 Proceder con feature engineering y entrenamiento
  📊 Implementar validación temporal robusta"""
    elif quality_eval['readiness_percentage'] >= 50:
        report += """  ⚠️ Dataset ACEPTABLE con mejoras recomendadas
  🔧 Aplicar técnicas de preprocesamiento robustas
  📊 Manejar outliers y eventos extremos"""
    else:
        report += """  ❌ Dataset necesita TRABAJO significativo
  🛠️ Preprocesamiento extensivo requerido
  🎯 Considerar recolección de más datos"""
    
    return report
