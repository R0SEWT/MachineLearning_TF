# ü§ñ Machine Learning Models - Sistema Completo

## üìñ Descripci√≥n

Directorio principal que contiene todo el sistema de Machine Learning para identificar criptomonedas de baja capitalizaci√≥n con alto potencial de retorno. Incluye pipeline de entrenamiento, optimizaci√≥n autom√°tica con Optuna, an√°lisis de resultados y integraci√≥n autom√°tica.

## üìÅ Estructura de Archivos

```
code/Models/
‚îú‚îÄ‚îÄ üß† crypto_ml_trainer.py              # Pipeline principal de entrenamiento
‚îú‚îÄ‚îÄ üöÄ crypto_ml_trainer_optimized.py    # Trainer con hiperpar√°metros optimizados
‚îú‚îÄ‚îÄ üîß crypto_hyperparameter_optimizer.py # Sistema Optuna completo
‚îú‚îÄ‚îÄ ‚ö° quick_optimization.py             # Scripts de optimizaci√≥n r√°pida
‚îú‚îÄ‚îÄ üìä optuna_results_analyzer.py        # Analizador de resultados
‚îú‚îÄ‚îÄ üîó integrate_optimized_params.py     # Integrador autom√°tico
‚îú‚îÄ‚îÄ üß™ test_ml_system.py                 # Tests del sistema ML
‚îú‚îÄ‚îÄ üìñ README_OPTIMIZATION.md            # Documentaci√≥n optimizaci√≥n
‚îú‚îÄ‚îÄ üìÑ OPTUNA_IMPLEMENTATION_COMPLETED.md # Reporte implementaci√≥n
‚îú‚îÄ‚îÄ üìÑ integration_report.md             # Reporte de integraci√≥n
‚îú‚îÄ‚îÄ üíæ crypto_ml_trainer_backup_*.py     # Backups autom√°ticos
‚îú‚îÄ‚îÄ üìì Model_training.ipynb              # Entrenamiento legacy
‚îî‚îÄ‚îÄ üìÅ catboost_info/                    # Informaci√≥n CatBoost
```

## üöÄ Inicio R√°pido

### 1. Entrenamiento B√°sico
```bash
# Entrenar modelos con configuraci√≥n por defecto
python crypto_ml_trainer.py

# Entrenar con hiperpar√°metros optimizados (recomendado)
python crypto_ml_trainer_optimized.py
```

### 2. Optimizaci√≥n de Hiperpar√°metros
```bash
# Optimizaci√≥n r√°pida de XGBoost (recomendado para empezar)
python quick_optimization.py --mode quick-xgb --trials 30 --timeout 600

# Optimizaci√≥n completa de todos los modelos
python crypto_hyperparameter_optimizer.py

# An√°lisis de resultados
python optuna_results_analyzer.py
```

### 3. Tests del Sistema
```bash
# Verificar que todo funciona correctamente
python test_ml_system.py
```

## ü§ñ Modelos Implementados

### 1. üî• XGBoost
- **Algoritmo**: Extreme Gradient Boosting
- **Fortalezas**: Excelente performance general, manejo de overfitting
- **Optimizaci√≥n**: 9 hiperpar√°metros optimizables
- **Resultado**: AUC 0.9954 (CV), 0.8100 (Test) despu√©s de optimizaci√≥n

### 2. üí° LightGBM  
- **Algoritmo**: Light Gradient Boosting Machine
- **Fortalezas**: Entrenamiento muy r√°pido, eficiente en memoria
- **Optimizaci√≥n**: 9 hiperpar√°metros optimizables
- **Resultado**: AUC 0.6871, entrenamiento con early stopping

### 3. üê± CatBoost
- **Algoritmo**: Categorical Boosting
- **Fortalezas**: Manejo autom√°tico de variables categ√≥ricas
- **Optimizaci√≥n**: 8+ hiperpar√°metros optimizables
- **Resultado**: AUC 0.7620 (consistentemente el mejor modelo)

### 4. üé≠ Ensemble Voting
- **M√©todo**: Voto mayoritario de los 3 modelos
- **Objetivo**: Maximizar robustez y reducir overfitting
- **Configuraci√≥n**: Soft voting con probabilidades

## üîß Sistema de Optimizaci√≥n (Optuna)

### Caracter√≠sticas Principales
- ‚úÖ **Optimizaci√≥n autom√°tica** de hiperpar√°metros
- ‚úÖ **Validaci√≥n temporal** robusta (60/20/20 split)
- ‚úÖ **Cross-validation** 3-fold estratificado
- ‚úÖ **Persistencia completa** (SQLite + JSON + Pickle)
- ‚úÖ **Visualizaciones interactivas** con Plotly
- ‚úÖ **Integraci√≥n autom√°tica** de mejores par√°metros

### Espacios de B√∫squeda Configurados

#### XGBoost
```python
{
    'n_estimators': 100-1000 (step 50),
    'max_depth': 3-12,
    'learning_rate': 0.01-0.3 (log scale),
    'subsample': 0.6-1.0,
    'colsample_bytree': 0.6-1.0,
    'reg_alpha': 0-10,
    'reg_lambda': 0-10,
    'min_child_weight': 1-10,
    'gamma': 0-5
}
```

#### LightGBM
```python
{
    'n_estimators': 100-1000 (step 50),
    'max_depth': 3-12,
    'learning_rate': 0.01-0.3 (log scale),
    'subsample': 0.6-1.0,
    'colsample_bytree': 0.6-1.0,
    'reg_alpha': 0-10,
    'reg_lambda': 0-10,
    'min_child_samples': 5-100,
    'num_leaves': 10-300
}
```

#### CatBoost
```python
{
    'iterations': 100-1000 (step 50),
    'depth': 3-10,
    'learning_rate': 0.01-0.3 (log scale),
    'subsample': 0.6-1.0,
    'colsample_bylevel': 0.6-1.0,
    'l2_leaf_reg': 1-10,
    'min_data_in_leaf': 1-100,
    'bootstrap_type': ['Bayesian', 'Bernoulli']
}
```

## üìä Features y Variables

### Variables Objetivo
- **`high_return_30d`**: Retorno > 100% en 30 d√≠as (binaria)
- **`future_return_30d`**: Retorno exacto en 30 d√≠as (continua)
- **`return_category_30d`**: Categorizaci√≥n de retornos (multi-clase)

### Categor√≠as de Features (76 total)

#### 1. üìà T√©cnicas (20+)
- **Retornos**: 1d, 5d, 7d, 14d, 30d
- **Promedios m√≥viles**: SMA 5, 10, 20, 50, 200
- **Bandas Bollinger**: upper, lower, width, position
- **RSI**: Relative Strength Index
- **MACD**: Signal, histogram, crossovers
- **Stochastic**: %K, %D

#### 2. üí∞ Volumen (15+)
- **OBV**: On-Balance Volume
- **VWAP**: Volume Weighted Average Price
- **Volume ratios**: 7d, 30d
- **Dollar volume**: SMAs 7d, 30d
- **Volume spikes**: Detecci√≥n autom√°tica

#### 3. üöÄ Momentum (10+)
- **ROC**: Rate of Change (m√∫ltiples per√≠odos)
- **Momentum**: 5, 10, 20 per√≠odos
- **Momentum consistency**: Estabilidad direccional
- **Breakouts**: Detecci√≥n up/down

#### 4. üéØ Narrativa (10+)
- **Narrative encoding**: Codificaci√≥n categ√≥rica
- **Narrative rank**: Ranking dentro de narrativa
- **Narrative correlation**: Correlaci√≥n con precio
- **Narrative percentile**: Percentil de performance
- **Relative to narrative**: Performance relativa

#### 5. ‚è∞ Temporales (15+)
- **D√≠a de semana**: Efectos estacionales
- **Mes**: Tendencias mensuales
- **Trimestre**: Ciclos trimestrales
- **Es fin de semana**: Binaria
- **Es fin de mes**: Binaria
- **D√≠as desde inicio**: Madurez del token

#### 6. üé™ Soporte/Resistencia (10+)
- **Support/Resistance levels**: Niveles calculados
- **Distance to support/resistance**: Distancias
- **Strength indicators**: Fortaleza de niveles
- **Days since high/low**: D√≠as desde extremos

## üìã Comandos Principales

### üîß Optimizaci√≥n

```bash
# === OPTIMIZACI√ìN R√ÅPIDA (RECOMENDADO) ===
# Solo XGBoost (5-10 min)
python quick_optimization.py --mode quick-xgb --trials 30 --timeout 600

# Solo LightGBM (5-10 min) 
python quick_optimization.py --mode quick-lgb --trials 30 --timeout 600

# Solo CatBoost (5-10 min)
python quick_optimization.py --mode quick-cat --trials 30 --timeout 600

# === OPTIMIZACI√ìN EST√ÅNDAR ===
# Todos los modelos (30-90 min)
python quick_optimization.py --mode full --trials 50 --timeout 1800

# === OPTIMIZACI√ìN EXPERIMENTAL ===
# B√∫squeda extensiva (2-6 horas)
python quick_optimization.py --mode experimental --trials 200 --timeout 3600

# === OPTIMIZACI√ìN COMPLETA ===
# Sistema completo con todas las capacidades
python crypto_hyperparameter_optimizer.py
```

### üìä An√°lisis

```bash
# An√°lisis completo de resultados
python optuna_results_analyzer.py

# Comparar estudios previos
python quick_optimization.py --mode compare

# Ver visualizaciones generadas
# Se crean en ../../optimization_results/analysis_visualizations/
```

### üîó Integraci√≥n

```bash
# Integrar mejores par√°metros encontrados
python integrate_optimized_params.py

# Esto genera:
# - crypto_ml_trainer_optimized.py (trainer actualizado)
# - crypto_ml_trainer_backup_*.py (backup del original)
# - integration_report.md (reporte de cambios)
```

### üß™ Testing

```bash
# Verificar que todo funciona
python test_ml_system.py

# Ejecutar trainer optimizado
python crypto_ml_trainer_optimized.py
```

## üìà Interpretaci√≥n de Resultados

### M√©tricas Principales
- **CV Score**: Promedio de cross-validation (m√©trica objetivo)
- **Validation AUC**: Performance en conjunto de validaci√≥n  
- **Test AUC**: Performance final en conjunto de test
- **Feature Importance**: Importancia de cada caracter√≠stica

### Ranking Autom√°tico
El sistema genera rankings autom√°ticos:
1. ü•á Mejor modelo por AUC
2. ü•à Segundo mejor
3. ü•â Tercer mejor

### Visualizaciones Generadas
- **Historia de optimizaci√≥n**: Convergencia por trial
- **Importancia de par√°metros**: Qu√© hiperpar√°metros importan m√°s
- **Gr√°ficos de contorno**: Interacciones entre par√°metros
- **An√°lisis temporal**: Evoluci√≥n de experimentos

## üéØ Detecci√≥n de Oportunidades

### M√©todo
1. **Ensemble prediction**: Predicciones de todos los modelos
2. **Probability threshold**: Filtro por probabilidad (por defecto >50%)
3. **Ranking**: Ordenamiento por probabilidad descendente
4. **Top-K selection**: Selecci√≥n de mejores K oportunidades

### Output
```python
# Ejemplo de salida
üéØ Top 10 oportunidades detectadas:
    1. √çndice 28531: 0.769 probabilidad
    2. √çndice 28532: 0.754 probabilidad
    3. √çndice 17529: 0.745 probabilidad
    ...
```

## üíæ Persistencia y Versionado

### Archivos Generados Autom√°ticamente

#### Modelos Entrenados (`../../models/`)
- `xgboost_crypto_ml_[timestamp].model`
- `lightgbm_crypto_ml_[timestamp].txt`
- `catboost_crypto_ml_[timestamp].cbm`
- `feature_importance_[timestamp].json`

#### Resultados Optuna (`../../optimization_results/`)
- `optuna_studies.db` - Base de datos SQLite
- `optimization_summary_[timestamp].json` - Res√∫menes
- `evaluation_results_[timestamp].json` - Evaluaciones
- `best_configs_[timestamp].json` - Mejores configuraciones
- `optuna_studies_[timestamp].pkl` - Estudios completos
- `analysis_visualizations/` - Gr√°ficos HTML interactivos

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Modificar Espacios de B√∫squeda
Editar las funciones `optimize_*` en `crypto_hyperparameter_optimizer.py`:

```python
# Ejemplo: ampliar rango de n_estimators
'n_estimators': trial.suggest_int('n_estimators', 50, 2000, step=50)
```

### Cambiar M√©tricas de Optimizaci√≥n
```python
# En funciones objective()
scoring='roc_auc'      # Por defecto (AUC-ROC)
scoring='precision'    # Para maximizar precisi√≥n
scoring='f1'          # Para F1-score
scoring='recall'      # Para recall
```

### Configurar Timeouts y Trials
```python
# En main() de los scripts
N_TRIALS = 100              # N√∫mero de trials
TIMEOUT_PER_MODEL = 3600    # Timeout en segundos
```

## üö® Troubleshooting

### Problemas Comunes

#### "No se encontr√≥ archivo de datos"
```bash
# Verificar dataset principal
ls ../../data/crypto_ohlc_join.csv
```

#### "Import optuna could not be resolved"
```bash
# Instalar dependencias faltantes
conda activate ML-TF-G
pip install optuna plotly kaleido
```

#### "Optimization timeout reached"
- Normal si se alcanza el timeout configurado
- Los resultados parciales siguen siendo v√°lidos
- Aumentar timeout si es necesario

#### Performance muy baja
- Verificar balance de clases en datos
- Revisar que las features son informativas
- Considerar cambiar m√©tricas de optimizaci√≥n

### Logs y Debug
- Los estudios de Optuna se guardan autom√°ticamente
- Usar `verbose=True` en funciones para m√°s detalles
- Revisar `../../optimization_results/` para hist√≥ricos

## üìö Documentaci√≥n Adicional

- **`README_OPTIMIZATION.md`**: Gu√≠a completa de optimizaci√≥n
- **`OPTUNA_IMPLEMENTATION_COMPLETED.md`**: Reporte t√©cnico detallado
- **`integration_report.md`**: Reporte de integraci√≥n autom√°tica
- **`../../README.md`**: Documentaci√≥n principal del proyecto

## üéØ Pr√≥ximos Pasos

### Para Desarrollo
1. Ejecutar optimizaci√≥n r√°pida: `python quick_optimization.py --mode quick-xgb --trials 20`
2. Analizar resultados: `python optuna_results_analyzer.py`
3. Integrar mejores par√°metros: `python integrate_optimized_params.py`

### Para Producci√≥n
1. Optimizaci√≥n exhaustiva: `python crypto_hyperparameter_optimizer.py`
2. Validaci√≥n en datos nuevos
3. Implementar re-entrenamiento peri√≥dico
4. Monitorear performance en el tiempo

---

**ü§ñ Sistema completo de ML para maximizar retornos en criptomonedas de baja capitalizaci√≥n** üöÄüí∞üìà
