{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93575084",
   "metadata": {},
   "source": [
    "## ðŸ”— Merge maestro de OHLC horarios  \n",
    "Este paso combina el `crypto_ohlc_join.csv` (dataset de referencia con mÃ©tricas\n",
    "fundamentales/narrativa, etc.) con los OHLC ðŸ“ˆ de **CryptoCompare (fuente\n",
    "principal)**, Binance y CoinGecko:\n",
    "\n",
    "* Se usa la clave `(symbol, timestamp)` donde `timestamp` son **segundos UTC**\n",
    "  de cada hora.  \n",
    "* Se hace un *outer merge* para **no perder ningÃºn dato**; si una fuente no\n",
    "  tiene esa hora, la celda queda `NaN`.\n",
    "* Los nombres de columnas OHLC llevan prefijo:  \n",
    "  `cc_open`, `bn_open`, `cg_open`, â€¦ para saber su procedencia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "056ebb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  ohlc_hourly_cryptocompare.csv NO encontrado.\n",
      "âš ï¸  ohlc_hourly_binance.csv NO encontrado.\n",
      "âš ï¸  ohlc_hourly_coingecko.csv NO encontrado.\n",
      "ðŸ—‚  Filas leÃ­das: {'master': 55684, 'cc': 0, 'binance': 0, 'gecko': 0}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['symbol', 'timestamp'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 62\u001b[39m\n\u001b[32m     59\u001b[39m merge_cols = [\u001b[33m\"\u001b[39m\u001b[33msymbol\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# â”€â”€ mantener solo lo necesario de cada fuente y poner prefijos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m cc      = \u001b[43madd_prefix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m     \u001b[49m\u001b[43m[\u001b[49m\u001b[43mmerge_cols\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcc_\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     63\u001b[39m binance = add_prefix(binance,\u001b[33m\"\u001b[39m\u001b[33mbn\u001b[39m\u001b[33m\"\u001b[39m)  [merge_cols + [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m binance.columns \u001b[38;5;28;01mif\u001b[39;00m c.startswith(\u001b[33m\"\u001b[39m\u001b[33mbn_\u001b[39m\u001b[33m\"\u001b[39m)]]\n\u001b[32m     64\u001b[39m gecko   = add_prefix(gecko, \u001b[33m\"\u001b[39m\u001b[33mcg\u001b[39m\u001b[33m\"\u001b[39m)   [merge_cols + [c \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m gecko.columns \u001b[38;5;28;01mif\u001b[39;00m c.startswith(\u001b[33m\"\u001b[39m\u001b[33mcg_\u001b[39m\u001b[33m\"\u001b[39m)]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['symbol', 'timestamp'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np, pathlib, time, datetime as dt\n",
    "from pandas.errors import EmptyDataError\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def safe_read(fp: pathlib.Path, **kwargs) -> pd.DataFrame:\n",
    "    \"\"\"Lee CSV si existe y no estÃ¡ vacÃ­o; retorna DF vacÃ­o en otro caso.\"\"\"\n",
    "    if not fp.exists():\n",
    "        print(f\"âš ï¸  {fp.name} NO encontrado.\")\n",
    "        return pd.DataFrame()\n",
    "    try:\n",
    "        return pd.read_csv(fp, **kwargs)\n",
    "    except EmptyDataError:\n",
    "        print(f\"âš ï¸  {fp.name} estÃ¡ vacÃ­o.  Se omite.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def ensure_timestamp(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Asegura columna 'timestamp' (segundos UTC) a partir de 'date' o index.\"\"\"\n",
    "    if \"timestamp\" in df.columns:\n",
    "        return df\n",
    "    if \"date\" in df.columns:\n",
    "        # aceptar varios formatos (p. ej. 2024-07-08 13:00:00 o solo fecha)\n",
    "        df[\"timestamp\"] = (\n",
    "            pd.to_datetime(df[\"date\"], errors=\"coerce\", utc=True)\n",
    "              .fillna(0).astype(\"int64\") // 10**9\n",
    "        )\n",
    "    else:\n",
    "        # como Ãºltimo recurso intentar usar el Ã­ndice\n",
    "        if df.index.dtype == \"datetime64[ns]\":\n",
    "            df = df.reset_index().rename(columns={\"index\": \"date\"})\n",
    "            df[\"timestamp\"] = df[\"date\"].astype(\"int64\") // 10**9\n",
    "    return df\n",
    "\n",
    "def add_prefix(df: pd.DataFrame, pref: str) -> pd.DataFrame:\n",
    "    \"\"\"Renombra columnas OHLC con prefijo (openâ†’pref_open, etc.).\"\"\"\n",
    "    rename_map = {c: f\"{pref}_{c}\" for c in df.columns\n",
    "                  if c in {\"open\",\"high\",\"low\",\"close\",\"volume\"}}\n",
    "    return df.rename(columns=rename_map)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ rutas â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "base = pathlib.Path(\"\")\n",
    "paths = {\n",
    "    \"master\":        base / \"crypto_ohlc_join.csv\",\n",
    "    \"cc\":            base / \"ohlc_hourly_cryptocompare.csv\",\n",
    "    \"binance\":       base / \"ohlc_hourly_binance.csv\",\n",
    "    \"gecko\":         base / \"ohlc_hourly_coingecko.csv\",\n",
    "}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ carga & preparaciÃ³n â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "master  = ensure_timestamp(safe_read(paths[\"master\"]))\n",
    "cc      = ensure_timestamp(safe_read(paths[\"cc\"]))\n",
    "binance = ensure_timestamp(safe_read(paths[\"binance\"]))\n",
    "gecko   = ensure_timestamp(safe_read(paths[\"gecko\"]))\n",
    "\n",
    "print(\"ðŸ—‚  Filas leÃ­das:\",\n",
    "      {k: len(v) for k,v in\n",
    "       ((\"master\", master),(\"cc\",cc),(\"binance\",binance),(\"gecko\",gecko))})\n",
    "\n",
    "# columnas mÃ­nimas para merge\n",
    "merge_cols = [\"symbol\",\"timestamp\"]\n",
    "\n",
    "# â”€â”€ mantener solo lo necesario de cada fuente y poner prefijos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cc      = add_prefix(cc,  \"cc\")     [merge_cols + [c for c in cc.columns if c.startswith(\"cc_\")]]\n",
    "binance = add_prefix(binance,\"bn\")  [merge_cols + [c for c in binance.columns if c.startswith(\"bn_\")]]\n",
    "gecko   = add_prefix(gecko, \"cg\")   [merge_cols + [c for c in gecko.columns if c.startswith(\"cg_\")]]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ merge incremental â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "merged = master.copy()\n",
    "for src_df in (cc, binance, gecko):\n",
    "    if src_df.empty:          # si la fuente no tiene datos la saltamos\n",
    "        continue\n",
    "    merged = merged.merge(src_df, on=merge_cols, how=\"outer\")\n",
    "\n",
    "print(\"âœ…  Filas finales:\", len(merged))\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ guardar â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "out_fp = base / \"crypto_ohlc_join_hourly_full.csv\"\n",
    "merged.to_csv(out_fp, index=False)\n",
    "print(\"ðŸ’¾ Guardado:\", out_fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326f15b7",
   "metadata": {},
   "source": [
    "## 1. Normalizar columnas bÃ¡sicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5ca9e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prep(df, src_name):\n",
    "    if df.empty:\n",
    "        return df\n",
    "    # Unificar nombres\n",
    "    rename_map = {\n",
    "        'open':'open_'+src_name,\n",
    "        'high':'high_'+src_name,\n",
    "        'low':'low_'+src_name,\n",
    "        'close':'close_'+src_name,\n",
    "        'volume':'volume_'+src_name\n",
    "    }\n",
    "    df = df.rename(columns=rename_map)\n",
    "    # Timestamp a UTC datetime sin zona\n",
    "    if 'timestamp' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s', utc=True).dt.tz_convert(None)\n",
    "    elif 'date' in df.columns:\n",
    "        df['timestamp'] = pd.to_datetime(df['date'], utc=True).dt.tz_convert(None)\n",
    "    # SÃ­mbolo upper\n",
    "    if 'symbol' in df.columns:\n",
    "        df['symbol'] = df['symbol'].str.upper()\n",
    "    return df\n",
    "\n",
    "master  = prep(master, 'master')\n",
    "binance = prep(binance, 'binance')\n",
    "cc      = prep(cc, 'cc')\n",
    "gecko   = prep(gecko, 'gecko')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d72c67",
   "metadata": {},
   "source": [
    "## 2. Combinar (outer join) sobre `symbol` + `timestamp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61a9de33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full shape: (55684, 11)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from functools import reduce\n",
    "\n",
    "dfs = [master, binance, cc, gecko]\n",
    "dfs = [d for d in dfs if not d.empty]\n",
    "\n",
    "full = reduce(lambda left,right: pd.merge(\n",
    "                left, right, on=['symbol','timestamp'], how='outer', suffixes=('','')), dfs)\n",
    "\n",
    "# Ordenar\n",
    "full = full.sort_values(['symbol','timestamp']).reset_index(drop=True)\n",
    "print(\"Full shape:\", full.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b849b7a",
   "metadata": {},
   "source": [
    "## 3. Guardar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edb7c55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‘ Guardado crypto_ohlc_join_full.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "out_fp = DATA_DIR / \"crypto_ohlc_join_full.csv\"\n",
    "full.to_csv(out_fp, index=False)\n",
    "print(\"ðŸ“‘ Guardado\", out_fp.relative_to(DATA_DIR.parent))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
