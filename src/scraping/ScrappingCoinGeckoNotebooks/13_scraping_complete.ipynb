{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5616f691",
   "metadata": {},
   "source": [
    "# üìà CoinGecko Scraper ‚Äì Balanced & Complete (v13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f505989",
   "metadata": {},
   "source": [
    "### 0 ¬∑ Instalar dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3698868",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -q pycoingecko aiohttp aiodns pandas tqdm pyarrow nest_asyncio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035e5621",
   "metadata": {},
   "source": [
    "### 1 ¬∑ Par√°metros y utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ab5356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio, aiohttp, nest_asyncio, pandas as pd, json, pathlib, time, random, tqdm\n",
    "nest_asyncio.apply()\n",
    "\n",
    "VS_CCY='usd'\n",
    "PAGES_MARKET=40\n",
    "MAX_MCAP=3e8\n",
    "MAX_MCAP_SPECIAL=1.2e9   # l√≠mite especial para AI/RWA\n",
    "CONCURRENCY=8            # menos 429\n",
    "RETRIES_INFO=5\n",
    "\n",
    "EXT_KEYWORDS={\n",
    "    'ai':[' ai ','artificial intelligence','machine learning','deep learning','big data','neural','analytics','data science','ml','agent','llm','gpt'],\n",
    "    'gaming':['game','gaming','metaverse','p2e','play to earn','gamefi','nft game','virtual world'],\n",
    "    'rwa':['real world asset','real-world','rwa','treasury','treasuries','bond','tokenized asset','tokenisation','tokenized treasury','real estate','gold','tokenised','tokenized bond'],\n",
    "    'meme':['meme','doge','dogecoin','pepe','shib','shiba','inu','floki','cat','wojak','kabosu']\n",
    "}\n",
    "\n",
    "def detect_narrative(info,cid):\n",
    "    parts=info.get('categories',[])+info.get('description',{}).get('en','').split()\n",
    "    parts+=[ t if isinstance(t,str) else t.get('name','') for t in info.get('tags',[]) ]\n",
    "    parts+=[info.get('symbol',''), info.get('name',''), cid]\n",
    "    blob=' '.join(parts).lower()\n",
    "    for nar,kws in EXT_KEYWORDS.items():\n",
    "        if any(kw in blob for kw in kws):\n",
    "            return nar\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5a3fd7",
   "metadata": {},
   "source": [
    "### 2 ¬∑ Descarga mercado as√≠ncrona (manejo 429 + cach√©)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "383eeec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ mercado cargado de cach√©\n",
      "Tokens totales: 1250\n"
     ]
    }
   ],
   "source": [
    "async def fetch_market(sess,page,retries=3):\n",
    "    url='https://api.coingecko.com/api/v3/coins/markets'\n",
    "    params=dict(vs_currency=VS_CCY, per_page=250, page=page, sparkline='false')\n",
    "    for att in range(retries):\n",
    "        async with sess.get(url,params=params,timeout=30) as r:\n",
    "            if r.status==429:\n",
    "                await asyncio.sleep(1.5+att)\n",
    "                continue\n",
    "            if r.status!=200:\n",
    "                return []\n",
    "            try:\n",
    "                return await r.json()\n",
    "            except aiohttp.ContentTypeError:\n",
    "                await asyncio.sleep(1+att)\n",
    "    return []\n",
    "\n",
    "async def gather_markets(pages):\n",
    "    async with aiohttp.ClientSession() as sess:\n",
    "        tasks=[fetch_market(sess,p) for p in pages]\n",
    "        data=[]\n",
    "        for coro in tqdm.tqdm(asyncio.as_completed(tasks), total=len(tasks)):\n",
    "            data+=await coro\n",
    "        return data\n",
    "\n",
    "cache_path=pathlib.Path('markets_cache.json')\n",
    "markets=None\n",
    "if cache_path.exists():\n",
    "    try:\n",
    "        markets=json.loads(cache_path.read_text())\n",
    "        df_test=pd.DataFrame(markets)\n",
    "        if {'id','symbol','name','market_cap'}.issubset(df_test.columns):\n",
    "            print('üìÑ mercado cargado de cach√©')\n",
    "        else:\n",
    "            markets=None\n",
    "    except Exception:\n",
    "        markets=None\n",
    "\n",
    "if markets is None:\n",
    "    start=time.time()\n",
    "    markets=asyncio.get_event_loop().run_until_complete(gather_markets(range(1,PAGES_MARKET+1)))\n",
    "    cache_path.write_text(json.dumps(markets))\n",
    "    print(f'‚è±Ô∏è mercado descargado en {time.time()-start:.1f}s')\n",
    "\n",
    "df_mk=pd.DataFrame(markets)\n",
    "candidates=df_mk[['id','symbol','name','market_cap']].reset_index(drop=True)\n",
    "print('Tokens totales:', len(candidates))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aff650d",
   "metadata": {},
   "source": [
    "### 3 ¬∑ Detalles + narrativa (retries & filtros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d61cc28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slugs elegidos por narrativa:\n",
      "¬∑ ai       ‚Üí 73 slugs encontrados. Ej: ['8bit-chain-ecosystem', 'ai-agent-launchpad', 'ai-agents', 'ai-applications']\n",
      "¬∑ gaming   ‚Üí 24 slugs encontrados. Ej: ['action-games', 'adventure-games', 'arcade-games', 'card-games']\n",
      "¬∑ rwa      ‚Üí 12 slugs encontrados. Ej: ['real-world-assets-rwa', 'rwa-protocol', 'tokenized-products', 'tokenized-btc']\n",
      "¬∑ meme     ‚Üí 26 slugs encontrados. Ej: ['ai-applications', 'ai-meme-coins', 'base-meme-coins', 'cat-themed-coins']\n",
      "------------------------------\n",
      "Iniciando descarga de 2025 p√°ginas para 135 slugs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2025/2025 [24:44<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è±Ô∏è  Descarga completada en: 1484.7s ‚Äî Filas brutas obtenidas: 993\n",
      "\n",
      "Distribuci√≥n de narrativas en el dataset final:\n",
      "narrative\n",
      "meme      496\n",
      "ai        425\n",
      "gaming     61\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Total de tokens √∫nicos obtenidos: 982\n",
      "‚ö†Ô∏è  Advertencia: A√∫n no se alcanz√≥ el objetivo de 5,000 tokens. Considera aumentar `PAGES_PER_CAT` o a√±adir m√°s `KEYWORDS`.\n",
      "üìÅ Datos guardados en cryptos_filtered.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### 3 ¬∑ Descarga masiva por categor√≠as para obtener >5,000 tokens\n",
    "\n",
    "import asyncio\n",
    "import aiohttp\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import time\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# --- Par√°metros de la descarga ---\n",
    "# Narrativas y palabras clave para identificar las categor√≠as (slugs) en CoinGecko\n",
    "KEYWORDS = {\n",
    "    \"ai\":     [\"ai\", \"artificial\", \"big-data\", \"machine-learning\"],\n",
    "    \"gaming\": [\"game\", \"gaming\", \"metaverse\", \"play-to-earn\"],\n",
    "    \"rwa\":    [\"real-world\", \"rwa\", \"tokenized\", \"real-estate\"],\n",
    "    \"meme\":   [\"meme\", \"dog\", \"cat\", \"pepe\", \"shiba\"],\n",
    "}\n",
    "\n",
    "# Aumentamos las p√°ginas por categor√≠a para asegurar m√°s de 5,000 tokens.\n",
    "# Con ~124 slugs en total y 250 tokens/p√°gina, 5 p√°ginas es suficiente, pero usamos 15 para tener margen.\n",
    "PAGES_PER_CAT = 15\n",
    "CONCURRENCY   = 12         # N√∫mero de descargas simult√°neas\n",
    "VS_CCY        = 'usd'      # Moneda de referencia\n",
    "\n",
    "# --- 1. Descubrir slugs (categor√≠as) reales desde la API de CoinGecko ---\n",
    "async def get_cat_list():\n",
    "    \"\"\"Obtiene la lista completa de categor√≠as de CoinGecko.\"\"\"\n",
    "    url = \"https://api.coingecko.com/api/v3/coins/categories/list\"\n",
    "    async with aiohttp.ClientSession() as sess:\n",
    "        try:\n",
    "            async with sess.get(url, timeout=30) as r:\n",
    "                if r.status == 200:\n",
    "                    return await r.json()\n",
    "                return []\n",
    "        except asyncio.TimeoutError:\n",
    "            print(\"Timeout al obtener la lista de categor√≠as.\")\n",
    "            return []\n",
    "\n",
    "# Ejecutamos la obtenci√≥n de categor√≠as\n",
    "cat_list = asyncio.get_event_loop().run_until_complete(get_cat_list())\n",
    "\n",
    "def pick_slugs(keyword_list):\n",
    "    \"\"\"Filtra los slugs de categor√≠as que coinciden con nuestras palabras clave.\"\"\"\n",
    "    return [\n",
    "        c[\"category_id\"]\n",
    "        for c in cat_list\n",
    "        if any(kw in c[\"category_id\"] for kw in keyword_list)\n",
    "    ]\n",
    "\n",
    "# Mapeamos cada narrativa a su lista de slugs encontrados\n",
    "SLUG_MAP = { nar: pick_slugs(kws) for nar, kws in KEYWORDS.items() }\n",
    "\n",
    "print(\"Slugs elegidos por narrativa:\")\n",
    "total_slugs = 0\n",
    "for nar, slugs in SLUG_MAP.items():\n",
    "    total_slugs += len(slugs)\n",
    "    print(f\"¬∑ {nar:8} ‚Üí {len(slugs)} slugs encontrados. Ej: {slugs[:4]}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- 2. Descarga todas las p√°ginas para cada slug identificado ---\n",
    "async def fetch_cat_page(sess, slug, page, retries=3):\n",
    "    \"\"\"Descarga una p√°gina de tokens para una categor√≠a (slug) espec√≠fica.\"\"\"\n",
    "    url = \"https://api.coingecko.com/api/v3/coins/markets\"\n",
    "    params = dict(vs_currency=VS_CCY, category=slug, per_page=250, page=page, sparkline=\"false\")\n",
    "    \n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            async with sess.get(url, params=params, timeout=40) as r:\n",
    "                if r.status == 429:\n",
    "                    # Si nos excedemos, esperamos un tiempo antes de reintentar\n",
    "                    await asyncio.sleep(2 + attempt)\n",
    "                    continue\n",
    "                if r.status == 200:\n",
    "                    data = await r.json()\n",
    "                    return data if isinstance(data, list) else []\n",
    "                return [] # Ignorar otros errores de servidor\n",
    "        except (aiohttp.ContentTypeError, asyncio.TimeoutError):\n",
    "            await asyncio.sleep(1.5 + attempt)\n",
    "    return []\n",
    "\n",
    "async def gather_all_narratives(slug_map):\n",
    "    \"\"\"Orquesta la descarga concurrente de todos los tokens para todas las narrativas.\"\"\"\n",
    "    sem = asyncio.Semaphore(CONCURRENCY)\n",
    "    all_rows = []\n",
    "    \n",
    "    async with aiohttp.ClientSession() as sess:\n",
    "        # Define una tarea para cada p√°gina de cada slug\n",
    "        async def worker(nar, slug, pg):\n",
    "            async with sem:\n",
    "                data = await fetch_cat_page(sess, slug, pg)\n",
    "                for d in data:\n",
    "                    d[\"narrative\"] = nar # Asigna la narrativa correcta a cada token\n",
    "                all_rows.extend(data)\n",
    "\n",
    "        # Crea la lista de todas las tareas a ejecutar\n",
    "        tasks = [\n",
    "            worker(nar, slug, pg)\n",
    "            for nar, slugs in slug_map.items()\n",
    "            for slug in slugs\n",
    "            for pg in range(1, PAGES_PER_CAT + 1)\n",
    "        ]\n",
    "        \n",
    "        # Ejecuta las tareas con una barra de progreso\n",
    "        print(f\"Iniciando descarga de {len(tasks)} p√°ginas para {total_slugs} slugs...\")\n",
    "        for f in tqdm.tqdm(asyncio.as_completed(tasks), total=len(tasks)):\n",
    "            await f\n",
    "            \n",
    "    return all_rows\n",
    "\n",
    "# --- Ejecuci√≥n y guardado ---\n",
    "t0 = time.time()\n",
    "cat_rows = asyncio.get_event_loop().run_until_complete(gather_all_narratives(SLUG_MAP))\n",
    "print(f\"‚è±Ô∏è  Descarga completada en: {time.time()-t0:.1f}s ‚Äî Filas brutas obtenidas: {len(cat_rows):,}\")\n",
    "\n",
    "# --- 3. Limpieza de datos y guardado final ---\n",
    "if cat_rows:\n",
    "    df_meta = (\n",
    "        pd.DataFrame(cat_rows)\n",
    "        .rename(columns={\"current_price\": \"price\", \"total_volume\": \"volume\"})\n",
    "        [\n",
    "            [\"id\", \"symbol\", \"name\", \"narrative\", \"price\", \"volume\", \"market_cap\"]\n",
    "        ]\n",
    "        .drop_duplicates(\"id\") # Elimina duplicados si un token aparece en varias categor√≠as\n",
    "        .dropna(subset=['market_cap', 'price']) # Elimina tokens sin datos clave\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    print(\"\\nDistribuci√≥n de narrativas en el dataset final:\")\n",
    "    print(df_meta[\"narrative\"].value_counts(dropna=False), \"\\n\")\n",
    "    print(f\"Total de tokens √∫nicos obtenidos: {len(df_meta)}\")\n",
    "\n",
    "    if len(df_meta) < 5000:\n",
    "        print(\"‚ö†Ô∏è  Advertencia: A√∫n no se alcanz√≥ el objetivo de 5,000 tokens. Considera aumentar `PAGES_PER_CAT` o a√±adir m√°s `KEYWORDS`.\")\n",
    "    else:\n",
    "        print(\"‚úÖ ¬°√âxito! Se ha superado el umbral de 5,000 tokens.\")\n",
    "\n",
    "    df_meta.to_csv(\"cryptos_filtered.csv\", index=False)\n",
    "    print(\"üìÅ Datos guardados en cryptos_filtered.csv\")\n",
    "else:\n",
    "    print(\"‚ùå No se obtuvieron datos. Revisa la conexi√≥n o los par√°metros de la API.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb987e25",
   "metadata": {},
   "source": [
    "### 4 ¬∑ OHLC 365‚ÄØd as√≠ncrono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa9ac46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 982/982 [15:43<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OHLC guardado ‚Äî shape: (13855, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "async def fetch_ohlc(sess,cid,days=365,retries=4):\n",
    "    url=f'https://api.coingecko.com/api/v3/coins/{cid}/market_chart'\n",
    "    params=dict(vs_currency=VS_CCY, days=days, interval='daily')\n",
    "    for att in range(retries):\n",
    "        async with sess.get(url,params=params,timeout=30) as r:\n",
    "            if r.status==429:\n",
    "                await asyncio.sleep(1.5+att); continue\n",
    "            if r.status!=200: return []\n",
    "            try:\n",
    "                j=await r.json()\n",
    "            except aiohttp.ContentTypeError:\n",
    "                await asyncio.sleep(1+att); continue\n",
    "            return [{'id':cid,'date':pd.to_datetime(ts,unit='ms').date(),'close':price}\n",
    "                    for ts,price in j.get('prices',[])]\n",
    "    return []\n",
    "\n",
    "async def gather_ohlc(ids):\n",
    "    sem=asyncio.Semaphore(CONCURRENCY)\n",
    "    async with aiohttp.ClientSession() as sess:\n",
    "        async def bound(cid):\n",
    "            async with sem: return await fetch_ohlc(sess,cid)\n",
    "        tasks=[bound(cid) for cid in ids]\n",
    "        rows=[]\n",
    "        for coro in tqdm.tqdm(asyncio.as_completed(tasks), total=len(tasks)):\n",
    "            rows.extend(await coro)\n",
    "        return rows\n",
    "\n",
    "ohlc_rows=asyncio.get_event_loop().run_until_complete(gather_ohlc(df_meta['id'].tolist()))\n",
    "df_ohlc=pd.DataFrame(ohlc_rows).set_index(['date','id']).sort_index()\n",
    "df_ohlc.to_parquet('ohlc.parquet')\n",
    "df_ohlc.reset_index().to_csv('ohlc_full_13.csv',index=False)\n",
    "print('‚úÖ OHLC guardado ‚Äî shape:', df_ohlc.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
