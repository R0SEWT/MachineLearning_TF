{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42c0ac4a",
   "metadata": {},
   "source": [
    "# ğŸ“Š Dual Crypto Scraper (CryptoCompare + CoinMarketCap)\n",
    "Genera un CSV con â‰¥5â€¯000 tokens (AI, Gaming, RWA, Meme) y un OHLC de 365â€¯dÃ­as.\n",
    "\n",
    "**Instrucciones:**\n",
    "1. Crea claves gratuitas en [cryptocompare.com](https://www.cryptocompare.com/) y [coinmarketcap.com](https://coinmarketcap.com/api/).\n",
    "2. Pega tus claves en la celda de parÃ¡metros.\n",
    "3. Reinicia el kernel y ejecuta *RunÂ All*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3274f874",
   "metadata": {},
   "source": [
    "## 0Â Â· Instalar dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41c31b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install -q requests pandas aiohttp nest_asyncio tqdm pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9952050",
   "metadata": {},
   "source": [
    "## 1Â Â· ParÃ¡metros y utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "104cb7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, pandas as pd, re, asyncio, aiohttp, nest_asyncio, tqdm, datetime, time\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ğŸ”‘ Inserta tus claves API:\n",
    "CRYPTOCOMPARE_KEY = \"04b6720c1a883e4135d9c03af7775afb654338972208c9b378120cd8269ef2c3\"\n",
    "COINMARKETCAP_KEY = \"2ba3c859-8c6d-4b31-86b6-1c1bf752dcab\"\n",
    "\n",
    "HEADERS_CC  = {\"Authorization\": f\"Apikey {CRYPTOCOMPARE_KEY}\"}\n",
    "HEADERS_CMC = {\"X-CMC_PRO_API_KEY\": COINMARKETCAP_KEY}\n",
    "\n",
    "VS          = \"USD\"\n",
    "HIST_DAYS   = 365\n",
    "CONC_OHLC   = 20\n",
    "\n",
    "OUT_CSV  = \"cryptos_filtered.csv\"\n",
    "OUT_OHLC = \"ohlc_full.csv\"\n",
    "\n",
    "kw_ai  = r\"(\\bai\\b|artificial|machine learning|deep learning|big data|llm|agent)\"\n",
    "kw_gam = r\"(game|gaming|metaverse|p2e|play to earn|gamefi|esports)\"\n",
    "kw_rwa = r\"(rwa|tokenized|real[- ]world|treasury|bond|yield|asset)\"\n",
    "kw_mem = r\"(meme|doge|pepe|shib|inu|floki|wojak|kabosu|cat|frog)\"\n",
    "\n",
    "def tag(txt:str)->str|None:\n",
    "    t=txt.lower()\n",
    "    if re.search(kw_mem,t): return \"meme\"\n",
    "    if re.search(kw_gam,t): return \"gaming\"\n",
    "    if re.search(kw_ai, t): return \"ai\"\n",
    "    if re.search(kw_rwa,t): return \"rwa\"\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960766e2",
   "metadata": {},
   "source": [
    "## 2Â Â· CryptoCompare â€” top mcap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8e262e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando top mcap de CryptoCompare por pÃ¡ginas â€¦\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(MAX_PAGES):\n\u001b[32m      8\u001b[39m     params = {\u001b[33m\"\u001b[39m\u001b[33mlimit\u001b[39m\u001b[33m\"\u001b[39m: PER_PAGE, \u001b[33m\"\u001b[39m\u001b[33mpage\u001b[39m\u001b[33m\"\u001b[39m: page, \u001b[33m\"\u001b[39m\u001b[33mtsym\u001b[39m\u001b[33m\"\u001b[39m: VS, \u001b[33m\"\u001b[39m\u001b[33msign\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     data = requests.get(\u001b[43murl\u001b[49m, params=params, headers=HEADERS_CC,\n\u001b[32m     10\u001b[39m                         timeout=\u001b[32m60\u001b[39m).json()[\u001b[33m\"\u001b[39m\u001b[33mData\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:                       \u001b[38;5;66;03m# fin de lista real\u001b[39;00m\n\u001b[32m     12\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'url' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Descargando top mcap de CryptoCompare por pÃ¡ginas â€¦\")\n",
    "\n",
    "PER_PAGE  = 200\n",
    "MAX_PAGES = 30          # = 6 000 potencial\n",
    "records_cc, missing_raw = [], 0\n",
    "\n",
    "for page in range(MAX_PAGES):\n",
    "    params = {\"limit\": PER_PAGE, \"page\": page, \"tsym\": VS, \"sign\": \"true\"}\n",
    "    data = requests.get(url, params=params, headers=HEADERS_CC,\n",
    "                        timeout=60).json()[\"Data\"]\n",
    "    if not data:                       # fin de lista real\n",
    "        break\n",
    "    for t in data:\n",
    "        raw = t.get(\"RAW\", {}).get(VS)\n",
    "        if not raw:\n",
    "            missing_raw += 1\n",
    "            continue\n",
    "        nar = tag(f\"{t['CoinInfo']['FullName']} {t['CoinInfo']['Name']}\")\n",
    "        if not nar:\n",
    "            continue\n",
    "        records_cc.append({\n",
    "            \"id\": t[\"CoinInfo\"][\"Name\"],\n",
    "            \"symbol\": t[\"CoinInfo\"][\"Name\"],\n",
    "            \"name\": t[\"CoinInfo\"][\"FullName\"],\n",
    "            \"price\": raw[\"PRICE\"],\n",
    "            \"volume\": raw[\"VOLUME24HOURTO\"],\n",
    "            \"market_cap\": raw[\"MKTCAP\"],\n",
    "            \"narrative\": nar,\n",
    "        })\n",
    "    # sal del bucle solo si YA superaste 5 000 tokens Ãºtiles\n",
    "    if len(records_cc) >= 5200:\n",
    "        break\n",
    "\n",
    "print(f\"PÃ¡ginas procesadas: {page+1}, tokens vÃ¡lidos: {len(records_cc)}, sin RAW: {missing_raw}\")\n",
    "\n",
    "df_cc = pd.DataFrame(records_cc)\n",
    "if not df_cc.empty:\n",
    "    print(\"CryptoCompare narrativas:\\n\", df_cc[\"narrative\"].value_counts())\n",
    "else:\n",
    "    print(\"âš ï¸  AÃºn ningÃºn token coincide â€” sigue paginando o revisa keywords.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed173b13",
   "metadata": {},
   "source": [
    "## 3Â Â· CoinMarketCap â€” categorÃ­as AI, Gaming, Meme, RWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc4d0ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando listings de CoinMarketCap â€¦\n",
      "PÃ¡ginas procesadas: 20, tokens vÃ¡lidos: 1141\n",
      "narrative\n",
      "meme      666\n",
      "ai        277\n",
      "gaming    132\n",
      "rwa        66\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Descargando listings de CoinMarketCap â€¦\")\n",
    "PER_PAGE = 500\n",
    "MAX_PAGES = 20          # 20Ã—500 = 10 000\n",
    "records = []\n",
    "\n",
    "for i in range(MAX_PAGES):\n",
    "    start = 1 + i * PER_PAGE\n",
    "    params = {\"start\": start, \"limit\": PER_PAGE, \"convert\": VS}\n",
    "    url = \"https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest\"\n",
    "    data = requests.get(url, params=params, headers=HEADERS_CMC, timeout=60).json()[\"data\"]\n",
    "    if not data:\n",
    "        break\n",
    "    for c in data:\n",
    "        q = c[\"quote\"][VS]\n",
    "        nar = tag(f\"{c['name']} {c['symbol']}\")\n",
    "        if nar:\n",
    "            records.append({\n",
    "                \"cmc_id\": c[\"id\"],\n",
    "                \"symbol\": c[\"symbol\"],\n",
    "                \"name\": c[\"name\"],\n",
    "                \"price\": q[\"price\"],\n",
    "                \"volume\": q[\"volume_24h\"],\n",
    "                \"market_cap\": q[\"market_cap\"],\n",
    "                \"narrative\": nar,\n",
    "            })\n",
    "\n",
    "print(f\"PÃ¡ginas procesadas: {i+1}, tokens vÃ¡lidos: {len(records)}\")\n",
    "df_cc = pd.DataFrame(records)\n",
    "print(df_cc[\"narrative\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3db6f0",
   "metadata": {},
   "source": [
    "## 4Â Â· Guardar el CSV con los 1 143 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec55dcd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CSV guardado â†’ coinmarketcap_filtered.csv | filas: 1141\n"
     ]
    }
   ],
   "source": [
    "# --- guardar CSV CoinMarketCap -----------------------------------------\n",
    "OUT_CSV = \"coinmarketcap_filtered.csv\"\n",
    "\n",
    "cols = [\"cmc_id\", \"symbol\", \"name\", \"narrative\", \"price\", \"volume\", \"market_cap\"]\n",
    "df_cc[cols].to_csv(OUT_CSV, index=False)\n",
    "print(\"âœ… CSV guardado â†’\", OUT_CSV, \"| filas:\", len(df_cc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051ff4fb",
   "metadata": {},
   "source": [
    "## 5Â Â· OHLC 365Â dÃ­as desde CoinMarketCap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf803d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OHLC:   1%|          | 9/954 [00:02<03:02,  5.16it/s]C:\\Users\\USUARIO\\AppData\\Local\\Temp\\ipykernel_35048\\2507051003.py:20: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  \"date\": datetime.datetime.utcfromtimestamp(d[\"time\"]).strftime(\"%Y-%m-%d\"),\n",
      "OHLC: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 954/954 [00:14<00:00, 67.13it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â±ï¸ OHLC filas 20,130\n",
      "âœ… OHLC CSV guardado â†’ ohlc_full.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- OHLC 365 d via CryptoCompare (sÃ­ funciona en plan free) -----------\n",
    "import asyncio, aiohttp, nest_asyncio, tqdm, datetime, pandas as pd, time\n",
    "nest_asyncio.apply()\n",
    "\n",
    "VS = \"USD\"\n",
    "DAYS = 365\n",
    "CONC = 20\n",
    "OUT_OHLC = \"ohlc_full.csv\"\n",
    "\n",
    "async def fetch_ohlc(sess, sym):\n",
    "    url = \"https://min-api.cryptocompare.com/data/v2/histoday\"\n",
    "    params = {\"fsym\": sym, \"tsym\": VS, \"limit\": DAYS, \"sign\": \"true\"}\n",
    "    async with sess.get(url, params=params, headers=HEADERS_CC, timeout=20) as r:\n",
    "        j = await r.json()\n",
    "        if j.get(\"Response\") != \"Success\":\n",
    "            return []\n",
    "        return [\n",
    "            {\n",
    "                \"id\": sym,\n",
    "                \"date\": datetime.datetime.utcfromtimestamp(d[\"time\"]).strftime(\"%Y-%m-%d\"),\n",
    "                \"close\": d[\"close\"],\n",
    "            }\n",
    "            for d in j[\"Data\"][\"Data\"]\n",
    "        ]\n",
    "\n",
    "async def gather(symbols):\n",
    "    rows = []; sem = asyncio.Semaphore(CONC)\n",
    "    async with aiohttp.ClientSession() as sess:\n",
    "        async def worker(s):\n",
    "            async with sem:\n",
    "                try: rows.extend(await fetch_ohlc(sess, s))\n",
    "                except: pass\n",
    "        tasks = [worker(s) for s in symbols]\n",
    "        for _ in tqdm.tqdm(asyncio.as_completed(tasks), total=len(tasks), desc=\"OHLC\"):\n",
    "            await _\n",
    "    return rows\n",
    "\n",
    "symbols = df_cc[\"symbol\"].unique().tolist()\n",
    "t0 = time.time()\n",
    "rows = asyncio.get_event_loop().run_until_complete(gather(symbols))\n",
    "print(f\"â±ï¸ OHLC filas {len(rows):,}\")\n",
    "\n",
    "pd.DataFrame(rows).to_csv(OUT_OHLC, index=False)\n",
    "print(\"âœ… OHLC CSV guardado â†’\", OUT_OHLC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75063d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "listing = requests.get(\"https://api.coingecko.com/api/v3/coins/list\").json()\n",
    "sym2id = {c[\"symbol\"].upper(): c[\"id\"] for c in listing}\n",
    "df_cc[\"cg_id\"] = df_cc[\"symbol\"].str.upper().map(sym2id)\n",
    "df_ids = df_cc.dropna(subset=[\"cg_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d7a1d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OHLC CG:   5%|â–Œ         | 49/975 [00:04<01:03, 14.65it/s] C:\\Users\\USUARIO\\AppData\\Local\\Temp\\ipykernel_35048\\782267807.py:14: DeprecationWarning: datetime.datetime.utcfromtimestamp() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.fromtimestamp(timestamp, datetime.UTC).\n",
      "  \"date\": datetime.datetime.utcfromtimestamp(ts/1000).strftime(\"%Y-%m-%d\"),\n",
      "OHLC CG: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 975/975 [00:05<00:00, 180.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â±ï¸ filas: 1497 en 5.4 s\n",
      "âœ… Guardado ohlc_full_coingecko.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import aiohttp, asyncio, nest_asyncio, tqdm, datetime, pandas as pd, time\n",
    "nest_asyncio.apply()\n",
    "\n",
    "DAYS = 365; VS = \"usd\"; CONC = 20\n",
    "url_tpl = \"https://api.coingecko.com/api/v3/coins/{id}/market_chart\"\n",
    "\n",
    "async def fetch(sess, cg_id, sym):\n",
    "    params = {\"vs_currency\": VS, \"days\": DAYS, \"interval\": \"daily\"}\n",
    "    async with sess.get(url_tpl.format(id=cg_id), params=params, timeout=25) as r:\n",
    "        if r.status != 200: return []\n",
    "        j = await r.json()\n",
    "        return [\n",
    "            {\"id\": sym,\n",
    "             \"date\": datetime.datetime.utcfromtimestamp(ts/1000).strftime(\"%Y-%m-%d\"),\n",
    "             \"close\": price}\n",
    "            for ts, price in j.get(\"prices\", [])\n",
    "        ]\n",
    "\n",
    "async def gather(rows):\n",
    "    out=[]; sem=asyncio.Semaphore(CONC)\n",
    "    async with aiohttp.ClientSession() as sess:\n",
    "        async def worker(cg_id,sym):\n",
    "            async with sem:\n",
    "                try: out.extend(await fetch(sess,cg_id,sym))\n",
    "                except: pass\n",
    "        tasks=[worker(r.cg_id,r.symbol) for r in rows.itertuples()]\n",
    "        for _ in tqdm.tqdm(asyncio.as_completed(tasks), total=len(tasks), desc=\"OHLC CG\"):\n",
    "            await _\n",
    "    return out\n",
    "\n",
    "t0=time.time()\n",
    "rows = asyncio.get_event_loop().run_until_complete(gather(df_ids[[\"cg_id\",\"symbol\"]]))\n",
    "print(\"â±ï¸ filas:\", len(rows), \"en\", round(time.time()-t0,1), \"s\")\n",
    "pd.DataFrame(rows).to_csv(\"ohlc_full_coingecko.csv\", index=False)\n",
    "print(\"âœ… Guardado ohlc_full_coingecko.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdcad4a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '..\\..\\data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 42\u001b[39m\n\u001b[32m     39\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m] = pd.to_datetime(df[\u001b[33m\"\u001b[39m\u001b[33mtimestamp\u001b[39m\u001b[33m\"\u001b[39m], unit=\u001b[33m\"\u001b[39m\u001b[33mms\u001b[39m\u001b[33m\"\u001b[39m, utc=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     41\u001b[39m out_path = \u001b[33m\"\u001b[39m\u001b[33m../../data/ohlc_hourly_btc_usdt.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ… Guardado \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m filas en \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py:3986\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3975\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3977\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3978\u001b[39m     frame=df,\n\u001b[32m   3979\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3983\u001b[39m     decimal=decimal,\n\u001b[32m   3984\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3986\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3987\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3988\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3989\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    614\u001b[39m parent = Path(path).parent\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: '..\\..\\data'"
     ]
    }
   ],
   "source": [
    "# â–¸ 1. Instalar ccxt (solo la 1Âª vez) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "#    !pip install --quiet ccxt\n",
    "\n",
    "import ccxt\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# â–¸ 2. ConfiguraciÃ³n â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "exchange  = ccxt.binance()             # o ccxt.coinbasepro(), etc.\n",
    "symbol    = \"BTC/USDT\"                 # par a descargar\n",
    "tf        = \"1h\"                       # timeframe\n",
    "limit     = 1000                       # mÃ¡x. velas por request\n",
    "end_ts    = exchange.milliseconds()    # ahora\n",
    "start_ts  = exchange.milliseconds() - 365*24*60*60*1000  # 365 d atrÃ¡s\n",
    "\n",
    "all_ohlc = []\n",
    "\n",
    "# â–¸ 3. Bucle de paginado â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "while start_ts < end_ts:\n",
    "    batch = exchange.fetch_ohlcv(\n",
    "        symbol,\n",
    "        timeframe=tf,\n",
    "        since=start_ts,\n",
    "        limit=limit\n",
    "    )\n",
    "    if not batch:               # sin datos â†’ salimos\n",
    "        break\n",
    "\n",
    "    all_ohlc.extend(batch)\n",
    "    start_ts = batch[-1][0] + 60*60*1000   # avanzar 1 h\n",
    "\n",
    "    # respetar rate-limit\n",
    "    time.sleep(exchange.rateLimit / 1000)\n",
    "\n",
    "# â–¸ 4. A DataFrame + guardado â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cols = [\"timestamp\",\"open\",\"high\",\"low\",\"close\",\"volume\"]\n",
    "df   = pd.DataFrame(all_ohlc, columns=cols)\n",
    "df[\"date\"] = pd.to_datetime(df[\"timestamp\"], unit=\"ms\", utc=True)\n",
    "\n",
    "out_path = \"../../data/ohlc_hourly_btc_usdt.csv\"\n",
    "df.to_csv(out_path, index=False)\n",
    "print(f\"âœ… Guardado {len(df):,d} filas en {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "caa0e922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Guardado 8,760 filas en C:\\UPC\\2025-1\\MachineLearning\\TrabajoFinal\\MachineLearning_TF\\src\\data\\ohlc_hourly_btc_usdt.csv\n"
     ]
    }
   ],
   "source": [
    "# â–¸ Crear (si hace falta) la carpeta ../../data\n",
    "from pathlib import Path\n",
    "out_path = Path(\"../../data/ohlc_hourly_btc_usdt.csv\")\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# â–¸ Guardar el DataFrame\n",
    "df.to_csv(out_path, index=False)\n",
    "print(f\"âœ… Guardado {len(df):,} filas en {out_path.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc52e7fd",
   "metadata": {},
   "source": [
    "CryptoCompare â€“ histohour\n",
    "Usamos el endpoint https://min-api.cryptocompare.com/data/v2/histohour, que devuelve hasta 2 000 horas por llamada. 8 760 h â‰ˆ 365 dÃ­as â‡’ 5 peticiones bastan. Necesitas una API-KEY gratuita y la variable de entorno CRYPTOCOMPARE_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "000ff01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… guardadas 8,760 filas en ..\\..\\data\\ohlc_hourly_cryptocompare_btc_usdt.csv\n"
     ]
    }
   ],
   "source": [
    "# â–¸ CryptoCompare | velas OHLC hora-a-hora 365 dÃ­as\n",
    "import os, time, datetime as dt, requests, pandas as pd, pathlib\n",
    "\n",
    "# ---------- parÃ¡metros editables ----------\n",
    "FSYM, TSYM   = \"BTC\", \"USDT\"              # par deseado\n",
    "END_TS       = int(time.time())           # Ãºltimo timestamp (ahora)\n",
    "DAYS_BACK    = 365\n",
    "API_KEY      = os.getenv(\"CRYPTOCOMPARE_API_KEY\")\n",
    "OUT_PATH     = pathlib.Path(\"../../data/ohlc_hourly_cryptocompare_btc_usdt.csv\")\n",
    "\n",
    "# ---------- descarga en bloques de 2 000 h ----------\n",
    "limit  = 2000\n",
    "remain = DAYS_BACK * 24            # horas pendientes\n",
    "all_df = []\n",
    "\n",
    "while remain > 0:\n",
    "    grab  = min(limit, remain)\n",
    "    url   = (\"https://min-api.cryptocompare.com/data/v2/histohour?\"\n",
    "             f\"fsym={FSYM}&tsym={TSYM}&limit={grab-1}&toTs={END_TS}\")\n",
    "    r     = requests.get(url, headers={\"authorization\": f\"Apikey {API_KEY}\"})\n",
    "    r.raise_for_status()\n",
    "    data  = r.json()[\"Data\"][\"Data\"]\n",
    "    df    = pd.DataFrame(data)[[\"time\",\"open\",\"high\",\"low\",\"close\",\"volumefrom\",\"volumeto\"]]\n",
    "    all_df.append(df)\n",
    "    # prepara siguiente iteraciÃ³n\n",
    "    END_TS = df[\"time\"].min() - 1\n",
    "    remain -= grab\n",
    "    time.sleep(0.25)               # evita rate-limit\n",
    "\n",
    "ohlc = pd.concat(all_df).drop_duplicates(\"time\").sort_values(\"time\")\n",
    "ohlc[\"date\"] = pd.to_datetime(ohlc[\"time\"], unit=\"s\", utc=True)\n",
    "ohlc.to_csv(OUT_PATH, index=False)\n",
    "print(f\"âœ… guardadas {len(ohlc):,} filas en {OUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac86b03",
   "metadata": {},
   "source": [
    "2ï¸âƒ£ CoinGecko â€“ market_chart/range (intervalo = hourly)\n",
    "El endpoint pÃºblico de CoinGecko sÃ³lo entrega velas hourly para rangos â‰¤ 90 dÃ­as; por tanto dividimos el aÃ±o en 5 tramos de 73 dÃ­as (â‰ˆ 1 752 h)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f77bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â–¸ CoinGecko | velas OHLC hora-a-hora 365 dÃ­as\n",
    "import time, datetime as dt, requests, pandas as pd, pathlib\n",
    "\n",
    "COIN_ID  = \"bitcoin\"          # ID interno CoinGecko\n",
    "VS_CUR   = \"usd\"\n",
    "CHUNK_D  = 73                 # 73-dÃ­as â‰ˆ 1 752 h < 90-dÃ­as lÃ­mite\n",
    "DAYS     = 365\n",
    "base_url = \"https://api.coingecko.com/api/v3/coins\"\n",
    "\n",
    "end   = dt.datetime.utcnow()\n",
    "start = end - dt.timedelta(days=DAYS)\n",
    "ranges = []\n",
    "# genera ventanas deslizantes de 73 d\n",
    "while start < end:\n",
    "    r_end   = min(start + dt.timedelta(days=CHUNK_D), end)\n",
    "    ranges.append((int(start.timestamp()), int(r_end.timestamp())))\n",
    "    start = r_end\n",
    "\n",
    "frames = []\n",
    "for frm, to in ranges:\n",
    "    url = (f\"{base_url}/{COIN_ID}/market_chart/range?\"\n",
    "           f\"vs_currency={VS_CUR}&from={frm}&to={to}&interval=hourly\")\n",
    "    resp = requests.get(url)\n",
    "    resp.raise_for_status()\n",
    "    prices = resp.json()[\"prices\"]           # [ts, price]\n",
    "    df = pd.DataFrame(prices, columns=[\"time_ms\",\"price\"])\n",
    "    df[\"time\"] = (df[\"time_ms\"] // 1000).astype(int)\n",
    "    frames.append(df[[\"time\",\"price\"]])\n",
    "    time.sleep(1.2)                          # courteously limit\n",
    "\n",
    "prices = pd.concat(frames).drop_duplicates(\"time\").sort_values(\"time\")\n",
    "prices[\"date\"] = pd.to_datetime(prices[\"time\"], unit=\"s\", utc=True)\n",
    "\n",
    "# reconstruimos OHLC a partir del precio de cierre de cada hora\n",
    "ohlc = (\n",
    "    prices.set_index(\"date\")[\"price\"]\n",
    "    .resample(\"1H\").ohlc()\n",
    "    .reset_index()\n",
    ")\n",
    "OUT = \"../../data/ohlc_hourly_coingecko_btc_usd.csv\"\n",
    "ohlc.to_csv(OUT, index=False)\n",
    "print(f\"âœ… guardadas {len(ohlc):,} filas en {OUT}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
