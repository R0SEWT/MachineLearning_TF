# üìä INFORME: ESTRATEGIA DE MODELADO PARA CRIPTOMONEDAS DE BAJA CAPITALIZACI√ìN

## üéØ RESUMEN EJECUTIVO

Bas√°ndome en el an√°lisis exploratorio de datos (EDA) realizado y los objetivos del proyecto, este informe define la estrategia completa de modelado para **identificar criptomonedas de baja capitalizaci√≥n con alto potencial de valorizaci√≥n** en los pr√≥ximos meses.

**Objetivo Principal**: Desarrollar un sistema de ML que identifique tokens con market cap < $10M que puedan generar retornos superiores al 100% en 30 d√≠as.

---

## üìã AN√ÅLISIS DEL DATASET ACTUAL

### üìä **Caracter√≠sticas de los Datos**
- **55,685 observaciones** de datos hist√≥ricos OHLC
- **Per√≠odo**: Julio 2024 - Julio 2025 (12 meses de datos)
- **Variables disponibles**: close, date, id, cmc_id, market_cap, name, narrative, price, symbol, volume
- **Tokens √∫nicos**: ~200+ criptomonedas diferentes
- **Narrativas**: meme, ai, gaming, rwa, infrastructure, defi

### üéØ **Segmentaci√≥n por Market Cap**
```
Baja Capitalizaci√≥n (< $10M):    ~70% de tokens
Media Capitalizaci√≥n ($10-100M): ~20% de tokens  
Alta Capitalizaci√≥n (> $100M):   ~10% de tokens
```

### üìà **Distribuci√≥n por Narrativas** (Basado en EDA)
```
meme           ~40%    # Mayor volatilidad y potencial explosivo
ai             ~25%    # Narrativa en crecimiento, fundamentals s√≥lidos
gaming         ~15%    # Volatilidad media, dependiente de adopci√≥n
rwa            ~10%    # Menor volatilidad, crecimiento sostenido
infrastructure ~5%     # Tokens de utilidad, crecimiento a largo plazo
defi           ~5%     # Tokens DeFi diversos
```

---

## üéØ DEFINICI√ìN DEL PROBLEMA DE MODELADO

### üìå **Problema Principal**
**Predicci√≥n de Retornos a 30 d√≠as**: Clasificar tokens que generar√°n retornos > 100% en 30 d√≠as

### üéØ **Variables Objetivo Propuestas**

#### 1. **Clasificaci√≥n Binaria** (Modelo Principal)
```python
target_binary = "high_return_30d"  # 1 si retorno > 100% en 30 d√≠as, 0 si no
```

#### 2. **Clasificaci√≥n Multi-clase** (Modelo Secundario)
```python
target_multiclass = "return_category_30d"
# Categor√≠as:
# 0: "P√âRDIDA" (retorno < -20%)
# 1: "ESTABLE" (retorno entre -20% y +50%)  
# 2: "GANANCIA_MEDIA" (retorno entre +50% y +100%)
# 3: "GANANCIA_ALTA" (retorno > +100%)
```

#### 3. **Regresi√≥n** (Modelo de Apoyo)
```python
target_regression = "future_return_30d"  # Retorno exacto en % a 30 d√≠as
```

### üéØ **M√©tricas de √âxito**
- **Precisi√≥n**: >80% en identificar tokens con retorno >100%
- **Recall**: >70% para no perder oportunidades importantes
- **ROI Simulado**: >300% anual en backtesting
- **Sharpe Ratio**: >2.0 en estrategia de trading

---

## üîß INGENIER√çA DE CARACTER√çSTICAS

### üìä **Features Financieras** (Basadas en EDA)

#### 1. **Indicadores T√©cnicos**
```python
# Momentum
- RSI (14, 30 d√≠as)
- MACD y se√±al
- Stochastic Oscillator
- Williams %R

# Tendencia  
- SMA (5, 10, 20, 50 d√≠as)
- EMA (12, 26 d√≠as)
- Bollinger Bands (20 d√≠as)
- ADX (Direcci√≥n de tendencia)

# Volatilidad
- ATR (Average True Range)
- Volatilidad hist√≥rica (7, 14, 30 d√≠as)
- Bollinger Band Width
- Volatilidad vs media m√≥vil
```

#### 2. **Features de Volumen y Liquidez**
```python
# Volumen
- Volumen promedio (7, 14, 30 d√≠as)
- Ratio volumen actual / promedio
- OBV (On Balance Volume)
- VWAP (Volume Weighted Average Price)

# Liquidez
- Bid-ask spread estimado
- Market depth proxy
- Volume Rate of Change
- Accumulation/Distribution Line
```

#### 3. **Features de Market Cap y Valoraci√≥n**
```python
# Capitalizaci√≥n
- Market cap actual
- Ratio market cap / volumen
- Percentil de market cap en narrativa
- D√≠as desde market cap m√≠nimo/m√°ximo

# Comparativa con narrativa
- Performance vs promedio de narrativa
- Ranking dentro de narrativa
- Correlaci√≥n con l√≠deres de narrativa
```

### üß† **Features de Narrativa y Sentimiento**

#### 1. **Features de Narrativa**
```python
# Clasificaci√≥n por narrativa
- narrative_encoded (one-hot encoding)
- narrative_momentum (performance promedio narrativa)
- narrative_volatility (volatilidad promedio narrativa)
- narrative_market_share

# Timing de narrativa
- dias_desde_listing
- posicion_en_narrativa_ranking
- correlation_with_narrative_leaders
```

#### 2. **Features de Timing y Estacionalidad**
```python
# Temporales
- day_of_week
- day_of_month  
- month
- quarter
- is_weekend
- is_month_end

# Ciclos cripto
- days_since_bitcoin_ath
- bitcoin_dominance_trend
- altcoin_season_indicator
```

### üìà **Features de Momentum y Patrones**

#### 1. **Momentum Multi-per√≠odo**
```python
# Retornos hist√≥ricos
- return_1d, return_3d, return_7d, return_14d
- return_volatility_7d, return_volatility_30d
- max_return_7d, min_return_7d
- recovery_time_from_drawdown

# Aceleraci√≥n
- price_acceleration_3d
- volume_acceleration_7d
- momentum_consistency_score
```

#### 2. **Detecci√≥n de Patrones**
```python
# Patrones t√©cnicos
- breakout_from_resistance
- support_level_strength  
- consolidation_period_length
- trend_strength_score

# Anomal√≠as
- unusual_volume_spike
- price_gap_detection
- volatility_breakout
- correlation_breakdown
```

---

## ü§ñ ARQUITECTURA DE MODELOS

### üèóÔ∏è **Sistema de Modelos en Cascada**

#### 1. **Filtro Inicial - Modelo de Screening**
```python
# Objetivo: Filtrar tokens candidatos
# Input: Todos los tokens de baja cap
# Output: Top 20% de tokens prometedores
# Algoritmo: XGBoost optimizado para recall alto
# M√©tricas: Recall > 90%, Precisi√≥n > 30%
```

#### 2. **Clasificador Principal - Modelo de Predicci√≥n**
```python
# Objetivo: Predecir retornos altos (>100%)
# Input: Tokens filtrados del paso 1
# Output: Probabilidad de retorno >100% en 30 d√≠as
# Algoritmo: Ensemble (XGBoost + CatBoost + Neural Network)
# M√©tricas: Precisi√≥n > 80%, F1-Score > 0.75
```

#### 3. **Modelo de Regresi√≥n - Estimaci√≥n de Retorno**
```python
# Objetivo: Estimar retorno exacto esperado
# Input: Tokens clasificados como "prometedores"
# Output: Retorno esperado en % (0-500%)
# Algoritmo: LightGBM con regularizaci√≥n
# M√©tricas: RMSE < 50%, R¬≤ > 0.6
```

#### 4. **Modelo de Riesgo - Evaluaci√≥n de Downside**
```python
# Objetivo: Estimar riesgo de p√©rdida severa
# Input: Tokens prometedores
# Output: Probabilidad de p√©rdida > 50%
# Algoritmo: Isolation Forest + XGBoost
# M√©tricas: Precisi√≥n en detectar p√©rdidas > 85%
```

### üß† **Algoritmos Espec√≠ficos Recomendados**

#### 1. **XGBoost** (Modelo Principal)
```python
# Ventajas para cripto:
- Excelente con features num√©ricas y categ√≥ricas mixtas
- Robusto a outliers (com√∫n en cripto)
- Feature importance interpretable
- Optimizaci√≥n con Optuna ya implementada

# Configuraci√≥n recomendada:
xgb_params = {
    'objective': 'binary:logistic',
    'eval_metric': 'auc',
    'max_depth': 6,
    'learning_rate': 0.05,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
    'reg_alpha': 0.1,
    'reg_lambda': 1.0
}
```

#### 2. **CatBoost** (Modelo de Narrativas)
```python
# Ventajas para nuestro caso:
- Manejo nativo de features categ√≥ricas (narrativas)
- Menos overfitting en datos peque√±os
- Excelente con datos temporales

# Configuraci√≥n recomendada:
catboost_params = {
    'objective': 'Logloss',
    'eval_metric': 'AUC',
    'iterations': 1000,
    'learning_rate': 0.05,
    'depth': 6,
    'l2_leaf_reg': 3,
    'cat_features': ['narrative', 'cluster_id']
}
```

#### 3. **Red Neuronal** (Modelo de Patrones Complejos)
```python
# Arquitectura recomendada:
# Input: 50-100 features normalizadas
# Hidden: 3 capas (128, 64, 32 neuronas)
# Output: 1 neurona (sigmoid para probabilidad)
# Dropout: 0.3 en cada capa
# Regularizaci√≥n: L1/L2 combinada
```

---

## üìä ESTRATEGIA DE VALIDACI√ìN

### ‚è∞ **Validaci√≥n Temporal** (Crucial para cripto)

#### 1. **Walk-Forward Validation**
```python
# Divisi√≥n temporal estricta:
# Entrenamiento: Mes 1-8 
# Validaci√≥n: Mes 9-10
# Test: Mes 11-12

# Sin data leakage futuro
# Validaci√≥n realista de trading
```

#### 2. **Backtesting Financiero**
```python
# Simulaci√≥n de trading:
# Capital inicial: $10,000
# Max posiciones simult√°neas: 5
# Stop-loss: -30%
# Take-profit: +150%
# Comisiones: 0.1% por transacci√≥n

# M√©tricas de trading:
# - Sharpe Ratio > 2.0
# - Maximum Drawdown < 30%
# - Win Rate > 60%
# - Average Return per Trade > 25%
```

### üéØ **M√©tricas de Evaluaci√≥n**

#### 1. **M√©tricas de Clasificaci√≥n**
```python
# Precisi√≥n: % de predicciones correctas de "alta ganancia"
# Recall: % de oportunidades reales capturadas
# F1-Score: Balance entre precisi√≥n y recall
# AUC-ROC: Capacidad de ranking de oportunidades
```

#### 2. **M√©tricas Financieras**
```python
# ROI Total: Retorno total de la estrategia
# Sharpe Ratio: Retorno ajustado por riesgo
# Calmar Ratio: Retorno / Maximum Drawdown
# Hit Rate: % de trades ganadores
# Profit Factor: Ganancias totales / P√©rdidas totales
```

---

## üîç DETECCI√ìN DE OPORTUNIDADES

### üö® **Sistema de Alertas en Tiempo Real**

#### 1. **Trigger de Oportunidades**
```python
# Condiciones para alerta:
oportunidad_detectada = (
    modelo_probabilidad > 0.75 AND
    riesgo_estimado < 0.30 AND
    market_cap < 10_000_000 AND
    volumen_24h > promedio_7d * 2 AND
    RSI < 70  # No sobrecomprado
)
```

#### 2. **Scoring de Oportunidades**
```python
# Score compuesto (0-100):
opportunity_score = (
    probabilidad_ganancia * 40 +      # 40% peso
    retorno_esperado/100 * 30 +       # 30% peso  
    (1 - riesgo_estimado) * 20 +      # 20% peso
    momentum_score * 10               # 10% peso
)
```

### üìà **Estrategia de Portfolio**

#### 1. **Diversificaci√≥n por Narrativa**
```python
# Distribuci√≥n recomendada:
portfolio_allocation = {
    'meme': 0.40,        # Alta volatilidad, alto retorno
    'ai': 0.30,          # Fundamentals s√≥lidos
    'gaming': 0.15,      # Adopci√≥n creciente
    'rwa': 0.10,         # Estabilidad relativa
    'defi': 0.05         # Utilidad establecida
}
```

#### 2. **Gesti√≥n de Riesgo**
```python
# Reglas de trading:
max_position_size = 0.20    # 20% del capital por token
max_narrative_exposure = 0.50  # 50% en una narrativa
stop_loss = -0.30           # -30% stop loss
take_profit = 1.50          # +150% take profit
rebalance_frequency = "weekly"
```

---

## üõ†Ô∏è IMPLEMENTACI√ìN T√âCNICA

### üìã **Pipeline de Datos**

#### 1. **Preparaci√≥n de Features** 
```python
# code/EDA/utils/feature_engineering.py
def create_ml_features(df):
    """Crear todas las features para ML"""
    
    # Features t√©cnicas
    df = add_technical_indicators(df)
    df = add_volume_features(df)
    df = add_momentum_features(df)
    
    # Features de narrativa
    df = add_narrative_features(df)
    df = add_timing_features(df)
    
    # Target variables
    df = create_target_variables(df)
    
    return df

def create_target_variables(df):
    """Crear variables objetivo"""
    # Calcular retorno a 30 d√≠as
    df['future_return_30d'] = df.groupby('id')['close'].pct_change(periods=30).shift(-30)
    
    # Clasificaci√≥n binaria: retorno > 100%
    df['high_return_30d'] = (df['future_return_30d'] > 1.0).astype(int)
    
    # Clasificaci√≥n multi-clase
    conditions = [
        df['future_return_30d'] < -0.2,
        (df['future_return_30d'] >= -0.2) & (df['future_return_30d'] < 0.5),
        (df['future_return_30d'] >= 0.5) & (df['future_return_30d'] < 1.0),
        df['future_return_30d'] >= 1.0
    ]
    df['return_category_30d'] = np.select(conditions, [0, 1, 2, 3], default=1)
    
    return df
```

#### 2. **Entrenamiento de Modelos**
```python
# code/Models/model_training_enhanced.py
def train_ensemble_model(X_train, y_train, X_val, y_val):
    """Entrenar ensemble de modelos"""
    
    # Modelo 1: XGBoost
    xgb_model = train_xgboost(X_train, y_train, X_val, y_val)
    
    # Modelo 2: CatBoost  
    cat_model = train_catboost(X_train, y_train, X_val, y_val)
    
    # Modelo 3: Neural Network
    nn_model = train_neural_network(X_train, y_train, X_val, y_val)
    
    # Ensemble con voting
    ensemble = VotingClassifier([
        ('xgb', xgb_model),
        ('cat', cat_model), 
        ('nn', nn_model)
    ], voting='soft')
    
    ensemble.fit(X_train, y_train)
    return ensemble
```

#### 3. **Sistema de Predicci√≥n**
```python
# code/Models/prediction_system.py
def predict_opportunities(df_current):
    """Predecir oportunidades actuales"""
    
    # Preparar features
    features = create_ml_features(df_current)
    
    # Filtrar baja capitalizaci√≥n
    low_cap = features[features['market_cap'] < 10_000_000]
    
    # Predicciones del ensemble
    probabilities = ensemble_model.predict_proba(low_cap)[:, 1]
    expected_returns = regression_model.predict(low_cap)
    risk_scores = risk_model.predict(low_cap)
    
    # Crear ranking de oportunidades
    opportunities = pd.DataFrame({
        'token': low_cap['id'],
        'narrative': low_cap['narrative'],
        'probability': probabilities,
        'expected_return': expected_returns,
        'risk_score': risk_scores,
        'opportunity_score': calculate_opportunity_score(
            probabilities, expected_returns, risk_scores
        )
    })
    
    return opportunities.sort_values('opportunity_score', ascending=False)
```

### üöÄ **Sistema de Alertas**
```python
# code/Models/alert_system.py
def check_opportunities():
    """Verificar nuevas oportunidades"""
    
    # Obtener datos actuales
    current_data = get_latest_data()
    
    # Generar predicciones
    opportunities = predict_opportunities(current_data)
    
    # Filtrar alertas de alta calidad
    high_quality = opportunities[
        (opportunities['probability'] > 0.75) &
        (opportunities['risk_score'] < 0.30) &
        (opportunities['opportunity_score'] > 80)
    ]
    
    # Enviar alertas
    for _, opp in high_quality.iterrows():
        send_alert(opp)
    
    return high_quality
```

---

## üìä CRONOGRAMA DE IMPLEMENTACI√ìN

### üóìÔ∏è **Fase 1: Preparaci√≥n de Datos** (1-2 semanas)
- [ ] Completar feature engineering avanzado
- [ ] Crear variables objetivo (retornos a 30 d√≠as)
- [ ] Implementar validaci√≥n temporal
- [ ] Crear dataset de entrenamiento limpio

### üóìÔ∏è **Fase 2: Desarrollo de Modelos** (2-3 semanas)  
- [ ] Implementar baseline models (XGBoost, CatBoost)
- [ ] Optimizar hiperpar√°metros con Optuna
- [ ] Desarrollar ensemble de modelos
- [ ] Crear modelo de estimaci√≥n de riesgo

### üóìÔ∏è **Fase 3: Validaci√≥n y Backtesting** (1-2 semanas)
- [ ] Implementar walk-forward validation
- [ ] Ejecutar backtesting financiero completo
- [ ] Validar m√©tricas de trading
- [ ] Ajustar estrategia de portfolio

### üóìÔ∏è **Fase 4: Sistema de Producci√≥n** (1-2 semanas)
- [ ] Desarrollar pipeline de predicci√≥n automatizado
- [ ] Implementar sistema de alertas
- [ ] Crear dashboard de monitoreo
- [ ] Testing en entorno de producci√≥n

---

## üéØ M√âTRICAS DE √âXITO DEL PROYECTO

### üìä **KPIs Principales**
```
‚úÖ Precisi√≥n en predicci√≥n de retornos >100%: Meta > 80%
‚úÖ Recall de oportunidades reales: Meta > 70%  
‚úÖ ROI anual simulado: Meta > 300%
‚úÖ Sharpe Ratio de estrategia: Meta > 2.0
‚úÖ Maximum Drawdown: Meta < 30%
‚úÖ Win Rate en trades: Meta > 60%
```

### üìà **M√©tricas Secundarias**
```
‚Ä¢ Tiempo promedio de detecci√≥n de oportunidad: < 24 horas
‚Ä¢ N√∫mero de oportunidades detectadas por mes: 10-20
‚Ä¢ Precisi√≥n en estimaci√≥n de retorno exacto: ¬±30%
‚Ä¢ Falsos positivos por semana: < 5
‚Ä¢ Disponibilidad del sistema: > 99%
```

---

## üö® RIESGOS Y MITIGACIONES

### ‚ö†Ô∏è **Riesgos T√©cnicos**
1. **Overfitting a datos hist√≥ricos**
   - Mitigaci√≥n: Validaci√≥n temporal estricta, regularizaci√≥n agresiva

2. **Data leakage futuro**
   - Mitigaci√≥n: Pipeline de features sin lookahead bias

3. **Cambios en din√°micas del mercado**
   - Mitigaci√≥n: Reentrenamiento mensual, monitoreo de deriva

### ‚ö†Ô∏è **Riesgos Financieros**
1. **Volatilidad extrema en cripto**
   - Mitigaci√≥n: Stop-loss autom√°tico, diversificaci√≥n

2. **Liquidez limitada en low-cap**
   - Mitigaci√≥n: Filtros de volumen m√≠nimo, posiciones peque√±as

3. **Manipulaci√≥n de mercado**
   - Mitigaci√≥n: Detecci√≥n de anomal√≠as, filtros de calidad

---

## üèÜ CONCLUSIONES Y RECOMENDACIONES

### üéØ **Estrategia Recomendada**

1. **Enfoque en clasificaci√≥n binaria** para identificar tokens con potencial >100% retorno
2. **Sistema ensemble** combinando XGBoost, CatBoost y redes neuronales
3. **Validaci√≥n temporal estricta** para evitar overfitting
4. **Backtesting financiero** como m√©trica principal de √©xito
5. **Diversificaci√≥n por narrativa** para gesti√≥n de riesgo
6. **Sistema de alertas automatizado** para ejecuci√≥n en tiempo real

### üöÄ **Ventajas Competitivas**

- **Datos exclusivos**: Acceso a datos de m√∫ltiples narrativas
- **Features avanzadas**: Indicadores t√©cnicos y de sentimiento
- **Validaci√≥n robusta**: Backtesting financiero realista
- **Sistema completo**: Desde detecci√≥n hasta ejecuci√≥n
- **Gesti√≥n de riesgo**: Protecci√≥n contra downside severo

### üìä **Expectativas Realistas**

```
Escenario Conservador:  ROI anual 150-200%
Escenario Optimista:    ROI anual 300-500%  
Escenario Pesimista:    ROI anual 50-100%
```

**El √©xito del sistema depender√° de la calidad de la implementaci√≥n, la disciplina en la ejecuci√≥n y la adaptaci√≥n continua a las condiciones cambiantes del mercado cripto.**

---

**üìÖ Fecha del Informe**: Enero 2025  
**üéØ Estado**: Listo para Implementaci√≥n  
**üë• Equipo**: ML-TF-G  
**üìä Pr√≥ximo Paso**: Iniciar Fase 1 - Preparaci√≥n de Datos
