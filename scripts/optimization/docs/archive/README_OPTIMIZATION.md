# üîß Sistema de Optimizaci√≥n de Hiperpar√°metros con Optuna

## üìñ Descripci√≥n

Sistema completo de optimizaci√≥n de hiperpar√°metros para modelos de Machine Learning aplicados a criptomonedas de baja capitalizaci√≥n. Utiliza **Optuna** para encontrar autom√°ticamente los mejores hiperpar√°metros para XGBoost, LightGBM y CatBoost.

## üéØ Caracter√≠sticas

### ‚úÖ Optimizaci√≥n Autom√°tica
- **XGBoost**: n_estimators, max_depth, learning_rate, subsample, colsample_bytree, reg_alpha, reg_lambda, min_child_weight, gamma
- **LightGBM**: n_estimators, max_depth, learning_rate, subsample, colsample_bytree, reg_alpha, reg_lambda, min_child_samples, num_leaves
- **CatBoost**: iterations, depth, learning_rate, subsample, colsample_bylevel, l2_leaf_reg, min_data_in_leaf, bootstrap_type

### ‚úÖ Validaci√≥n Robusta
- **Split temporal**: 60% entrenamiento, 20% validaci√≥n, 20% test
- **Cross-validation**: 3-fold estratificado en entrenamiento
- **M√©tricas**: AUC-ROC como objetivo de optimizaci√≥n

### ‚úÖ Persistencia Completa
- **Base de datos SQLite** para estudios de Optuna
- **JSON** para res√∫menes y mejores par√°metros
- **Pickle** para objetos completos de estudios
- **Versionado autom√°tico** con timestamps

### ‚úÖ Visualizaciones Interactivas
- **Historia de optimizaci√≥n** por modelo
- **Importancia de par√°metros** 
- **Gr√°ficos de contorno** para correlaciones
- **Comparaci√≥n temporal** de experimentos
- **An√°lisis de sensibilidad** de hiperpar√°metros

### ‚úÖ An√°lisis Avanzado
- **Comparaci√≥n entre modelos** y experimentos
- **Evoluci√≥n temporal** de performance
- **Correlaciones** entre par√°metros y performance
- **Exportaci√≥n** de mejores configuraciones

## üìÅ Archivos del Sistema

```
code/Models/
‚îú‚îÄ‚îÄ crypto_hyperparameter_optimizer.py    # Optimizador principal
‚îú‚îÄ‚îÄ quick_optimization.py                 # Scripts de optimizaci√≥n r√°pida
‚îú‚îÄ‚îÄ optuna_results_analyzer.py           # Analizador de resultados
‚îî‚îÄ‚îÄ README_OPTIMIZATION.md               # Esta documentaci√≥n

optimization_results/                     # Resultados (auto-generados)
‚îú‚îÄ‚îÄ optuna_studies.db                    # Base de datos SQLite
‚îú‚îÄ‚îÄ optimization_summary_[timestamp].json # Res√∫menes por experimento
‚îú‚îÄ‚îÄ evaluation_results_[timestamp].json   # Evaluaciones en test
‚îú‚îÄ‚îÄ best_configs_[timestamp].json        # Mejores configuraciones
‚îî‚îÄ‚îÄ visualizations/                      # Gr√°ficos interactivos
    ‚îú‚îÄ‚îÄ xgboost/
    ‚îú‚îÄ‚îÄ lightgbm/
    ‚îî‚îÄ‚îÄ catboost/
```

## üöÄ C√≥mo Usar

### 1. Optimizaci√≥n Completa (Recomendado)
```bash
cd /home/exodia/Documentos/MachineLearning_TF/code/Models
conda activate ML-TF-G

# Optimizaci√≥n completa (todos los modelos)
python crypto_hyperparameter_optimizer.py
```

### 2. Optimizaci√≥n R√°pida por Modelo
```bash
# Solo XGBoost (30 trials, 10 min)
python quick_optimization.py --mode quick-xgb --trials 30 --timeout 600

# Solo LightGBM (30 trials, 10 min)
python quick_optimization.py --mode quick-lgb --trials 30 --timeout 600

# Solo CatBoost (30 trials, 10 min)
python quick_optimization.py --mode quick-cat --trials 30 --timeout 600
```

### 3. Optimizaci√≥n Personalizada
```bash
# Optimizaci√≥n completa personalizada
python quick_optimization.py --mode full --trials 100 --timeout 3600

# Optimizaci√≥n experimental (m√°s trials y tiempo)
python quick_optimization.py --mode experimental --trials 200 --timeout 7200
```

### 4. An√°lisis de Resultados
```bash
# Analizar todos los resultados previos
python optuna_results_analyzer.py

# Comparar estudios existentes
python quick_optimization.py --mode compare
```

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Modificar Espacios de B√∫squeda

Editar `crypto_hyperparameter_optimizer.py` en las funciones `optimize_*`:

```python
# Ejemplo para XGBoost
params = {
    'n_estimators': trial.suggest_int('n_estimators', 50, 2000, step=50),  # Rango ampliado
    'max_depth': trial.suggest_int('max_depth', 2, 15),                    # M√°s profundidad
    'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.5, log=True),  # Rango extendido
    # ... otros par√°metros
}
```

### Cambiar M√©tricas de Optimizaci√≥n

```python
# En las funciones objective(), cambiar:
scoring='roc_auc'  # Por defecto
# A:
scoring='precision'  # Para precisi√≥n
scoring='recall'     # Para recall
scoring='f1'         # Para F1-score
```

### Configurar Timeout y Trials

```python
# Configuraci√≥n en main()
N_TRIALS = 100              # N√∫mero de trials por modelo
TIMEOUT_PER_MODEL = 3600    # 1 hora por modelo
```

## üìä Interpretaci√≥n de Resultados

### M√©tricas Principales
- **CV Score**: Promedio de cross-validation (m√©trica objetivo)
- **Validation AUC**: Performance en conjunto de validaci√≥n
- **Test AUC**: Performance final en conjunto de test

### Ranking de Modelos
El sistema autom√°ticamente rankea los modelos por performance y muestra:
1. ü•á Mejor modelo general
2. ü•à Segundo mejor
3. ü•â Tercer mejor

### Hiperpar√°metros Importantes
El an√°lisis identifica autom√°ticamente qu√© hiperpar√°metros tienen mayor impacto en la performance mediante correlaciones.

## üéØ Estrategias de Optimizaci√≥n

### 1. B√∫squeda R√°pida (30-50 trials)
- **Tiempo**: 10-30 minutos por modelo
- **Objetivo**: Encontrar configuraciones decentes r√°pidamente
- **Uso**: Desarrollo y pruebas iniciales

### 2. B√∫squeda Est√°ndar (100 trials)
- **Tiempo**: 30-60 minutos por modelo  
- **Objetivo**: Buena optimizaci√≥n con tiempo razonable
- **Uso**: Entrenamiento regular de modelos

### 3. B√∫squeda Extensiva (200+ trials)
- **Tiempo**: 1-3 horas por modelo
- **Objetivo**: Encontrar los mejores hiperpar√°metros posibles
- **Uso**: Modelos de producci√≥n cr√≠ticos

### 4. B√∫squeda Continua
- **Configurar**: Timeout sin l√≠mite de trials
- **Objetivo**: Optimizaci√≥n continua en background
- **Uso**: Servidores dedicados para optimizaci√≥n

## üìà Visualizaciones Disponibles

### 1. Historia de Optimizaci√≥n
- Evoluci√≥n del mejor valor encontrado por trial
- Identifica convergencia y plateau

### 2. Importancia de Par√°metros
- Ranking de par√°metros por impacto en performance
- Ayuda a enfocar futuras optimizaciones

### 3. Gr√°ficos de Contorno
- Relaci√≥n entre pares de par√°metros
- Identifica interacciones entre hiperpar√°metros

### 4. Comparaci√≥n Temporal
- Evoluci√≥n de performance entre experimentos
- Muestra progreso a lo largo del tiempo

### 5. An√°lisis de Sensibilidad
- C√≥mo var√≠a la performance con cada par√°metro
- Identifica rangos √≥ptimos de valores

## üîÑ Flujo de Trabajo Recomendado

1. **Primera optimizaci√≥n**: `quick-optimization.py --mode full --trials 50`
2. **Analizar resultados**: `optuna_results_analyzer.py`
3. **Identificar modelo prometedor**: Revisar ranking y visualizaciones
4. **Optimizaci√≥n enfocada**: M√°s trials en el mejor modelo
5. **Validaci√≥n final**: Entrenar con mejores par√°metros y evaluar
6. **Monitoreo continuo**: Ejecutar optimizaciones peri√≥dicas

## üõ†Ô∏è Troubleshooting

### Error: "No se encontr√≥ archivo de datos"
```bash
# Verificar que existe el dataset
ls /home/exodia/Documentos/MachineLearning_TF/data/crypto_ohlc_join.csv
```

### Error: "Import optuna could not be resolved"
```bash
# Instalar optuna en el ambiente
conda activate ML-TF-G
pip install optuna plotly
```

### Warning: "Optimization timeout reached"
- Normal si se alcanza el timeout configurado
- Los resultados parciales siguen siendo v√°lidos
- Aumentar timeout o reducir trials si es necesario

### Performance muy baja
- Verificar que los datos est√°n balanceados
- Revisar que las features son informativas
- Considerar cambiar la m√©trica de optimizaci√≥n

## üìù Tips y Mejores Pr√°cticas

### üéØ Optimizaci√≥n Eficiente
1. **Empezar con pocos trials** para verificar funcionamiento
2. **Usar timeouts** para evitar experimentos infinitos
3. **Monitorear convergencia** en visualizaciones
4. **Ejecutar m√∫ltiples experimentos** para verificar reproducibilidad

### üìä An√°lisis de Resultados
1. **No confiar solo en CV score** - validar en test set
2. **Revisar importancia de par√°metros** antes de re-optimizar
3. **Comparar m√∫ltiples experimentos** para identificar tendencias
4. **Guardar configuraciones exitosas** para uso futuro

### üîß Configuraci√≥n de Par√°metros
1. **Usar rangos amplios** inicialmente
2. **Afinar rangos** basado en resultados previos
3. **Considerar interacciones** entre par√°metros
4. **Validar robustez** con diferentes semillas

## üéâ Pr√≥ximos Pasos

Una vez completada la optimizaci√≥n:

1. **Integrar mejores par√°metros** en `crypto_ml_trainer.py`
2. **Crear configuraci√≥n autom√°tica** desde archivos JSON
3. **Implementar re-optimizaci√≥n peri√≥dica** con nuevos datos
4. **Desarrollar alertas** para ca√≠das de performance
5. **Crear dashboard** para monitoreo continuo

---

**üîß Sistema desarrollado para maximizar la performance de modelos ML en detecci√≥n de oportunidades cripto** üöÄ
